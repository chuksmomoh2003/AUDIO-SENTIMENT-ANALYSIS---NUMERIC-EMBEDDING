{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ba0b10-2062-4819-9c81-3d622cf5c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e3092a-1704-42bb-aebb-6451c973aa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2\n"
     ]
    }
   ],
   "source": [
    "import autogluon.core\n",
    "print(autogluon.core.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256c0d0e-953d-4f9d-9c4f-e457362ef472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.wav</td>\n",
       "      <td>-580.87890</td>\n",
       "      <td>115.223640</td>\n",
       "      <td>15.318973</td>\n",
       "      <td>31.279287</td>\n",
       "      <td>17.988214</td>\n",
       "      <td>5.256765</td>\n",
       "      <td>-5.390493</td>\n",
       "      <td>6.711666</td>\n",
       "      <td>2.773420</td>\n",
       "      <td>2.796624</td>\n",
       "      <td>-2.878265</td>\n",
       "      <td>-0.381885</td>\n",
       "      <td>-5.367775</td>\n",
       "      <td>125.012856</td>\n",
       "      <td>84.077866</td>\n",
       "      <td>24.145555</td>\n",
       "      <td>26.235401</td>\n",
       "      <td>20.916960</td>\n",
       "      <td>12.164499</td>\n",
       "      <td>15.651846</td>\n",
       "      <td>9.862374</td>\n",
       "      <td>8.668188</td>\n",
       "      <td>8.708022</td>\n",
       "      <td>7.595624</td>\n",
       "      <td>10.063101</td>\n",
       "      <td>9.008025</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.wav</td>\n",
       "      <td>-580.95056</td>\n",
       "      <td>115.441700</td>\n",
       "      <td>15.418888</td>\n",
       "      <td>31.414440</td>\n",
       "      <td>17.996742</td>\n",
       "      <td>5.303187</td>\n",
       "      <td>-5.383050</td>\n",
       "      <td>6.772942</td>\n",
       "      <td>2.772726</td>\n",
       "      <td>2.835827</td>\n",
       "      <td>-2.922361</td>\n",
       "      <td>-0.413725</td>\n",
       "      <td>-5.415762</td>\n",
       "      <td>125.014540</td>\n",
       "      <td>83.915060</td>\n",
       "      <td>24.074612</td>\n",
       "      <td>26.121923</td>\n",
       "      <td>20.833368</td>\n",
       "      <td>12.171346</td>\n",
       "      <td>15.737186</td>\n",
       "      <td>9.787956</td>\n",
       "      <td>8.637162</td>\n",
       "      <td>8.751245</td>\n",
       "      <td>7.612542</td>\n",
       "      <td>10.058934</td>\n",
       "      <td>9.000790</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.wav</td>\n",
       "      <td>-572.78860</td>\n",
       "      <td>111.368324</td>\n",
       "      <td>10.172045</td>\n",
       "      <td>26.962570</td>\n",
       "      <td>13.831090</td>\n",
       "      <td>3.151526</td>\n",
       "      <td>-5.602227</td>\n",
       "      <td>5.504691</td>\n",
       "      <td>-2.488910</td>\n",
       "      <td>0.391467</td>\n",
       "      <td>-5.616608</td>\n",
       "      <td>4.138154</td>\n",
       "      <td>-1.604058</td>\n",
       "      <td>128.160800</td>\n",
       "      <td>82.202934</td>\n",
       "      <td>33.284805</td>\n",
       "      <td>18.766754</td>\n",
       "      <td>13.804071</td>\n",
       "      <td>12.640682</td>\n",
       "      <td>12.723204</td>\n",
       "      <td>10.600430</td>\n",
       "      <td>9.021395</td>\n",
       "      <td>9.876261</td>\n",
       "      <td>10.437687</td>\n",
       "      <td>9.282254</td>\n",
       "      <td>8.263548</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.wav</td>\n",
       "      <td>-598.74860</td>\n",
       "      <td>109.433556</td>\n",
       "      <td>20.036419</td>\n",
       "      <td>24.895813</td>\n",
       "      <td>19.323107</td>\n",
       "      <td>9.383337</td>\n",
       "      <td>-7.663574</td>\n",
       "      <td>4.774885</td>\n",
       "      <td>1.692682</td>\n",
       "      <td>1.436045</td>\n",
       "      <td>0.414321</td>\n",
       "      <td>0.342957</td>\n",
       "      <td>-6.313865</td>\n",
       "      <td>124.350845</td>\n",
       "      <td>86.817320</td>\n",
       "      <td>20.377861</td>\n",
       "      <td>19.933426</td>\n",
       "      <td>18.268124</td>\n",
       "      <td>12.460650</td>\n",
       "      <td>15.253509</td>\n",
       "      <td>9.825088</td>\n",
       "      <td>9.455122</td>\n",
       "      <td>9.935232</td>\n",
       "      <td>6.739247</td>\n",
       "      <td>9.231262</td>\n",
       "      <td>11.577960</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.wav</td>\n",
       "      <td>-547.26984</td>\n",
       "      <td>108.963070</td>\n",
       "      <td>16.372780</td>\n",
       "      <td>28.410503</td>\n",
       "      <td>11.128700</td>\n",
       "      <td>-2.526328</td>\n",
       "      <td>-4.537299</td>\n",
       "      <td>6.266095</td>\n",
       "      <td>-2.979559</td>\n",
       "      <td>3.482055</td>\n",
       "      <td>-5.172300</td>\n",
       "      <td>7.618698</td>\n",
       "      <td>1.229359</td>\n",
       "      <td>118.108480</td>\n",
       "      <td>72.307610</td>\n",
       "      <td>26.735168</td>\n",
       "      <td>19.858885</td>\n",
       "      <td>17.156792</td>\n",
       "      <td>12.323198</td>\n",
       "      <td>14.942352</td>\n",
       "      <td>13.315815</td>\n",
       "      <td>8.843205</td>\n",
       "      <td>8.530368</td>\n",
       "      <td>10.291992</td>\n",
       "      <td>8.748182</td>\n",
       "      <td>9.091330</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename          0           1  ...         24         25     Class\n",
       "0   28.wav -580.87890  115.223640  ...  10.063101   9.008025  Positive\n",
       "1   30.wav -580.95056  115.441700  ...  10.058934   9.000790  Positive\n",
       "2   36.wav -572.78860  111.368324  ...   9.282254   8.263548  Positive\n",
       "3    9.wav -598.74860  109.433556  ...   9.231262  11.577960  Positive\n",
       "4   16.wav -547.26984  108.963070  ...   8.748182   9.091330  Positive\n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('updated_audio_embeddings.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107fe11c-27f5-4570-b599-48d49457c425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241226_075449\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 23 17:17:00 UTC 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       22.41 GB / 30.89 GB (72.6%)\n",
      "Disk Space Avail:   28.32 GB / 49.99 GB (56.7%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-12-26 07:54:51,234\tWARNING services.py:2022 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 4034895872 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=7.91gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-12-26 07:54:51,386\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/home/sagemaker-user/AUDIO SENTIMENT ANALYSIS - NUMERIC EMBEDDING/AutogluonModels/ag-20241226_075449/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Beginning AutoGluon training ... Time limit = 897s\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m AutoGluon will save models to \"/home/sagemaker-user/AUDIO SENTIMENT ANALYSIS - NUMERIC EMBEDDING/AutogluonModels/ag-20241226_075449/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Train Data Rows:    222\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Train Data Columns: 27\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Label Column:       Class\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Problem Type:       multiclass\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Train Data Class Count: 3\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tAvailable Memory:                    22309.53 MB\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tUnused Original Features (Count: 1): ['Filename']\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t('object', []) : 1 | ['Filename']\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t('float', []) : 26 | ['0', '1', '2', '3', '4', ...]\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t('float', []) : 26 | ['0', '1', '2', '3', '4', ...]\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t26 features in original data used to generate 26 features in processed data.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 598.02s of the 897.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.8423\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 596.44s of the 895.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.8694\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 596.43s of the 895.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=4048)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t6.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 588.13s of the 887.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_ray_fit pid=4438)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=4438)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=4438)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4438)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=4438)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=4438)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4438)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=4437)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4437)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4432)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4432)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4436)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4436)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4431)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4431)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4433)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4433)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4434)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4434)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4435)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4435)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 583.39s of the 882.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_ray_fit pid=4041)\u001b[0m No improvement since epoch 8: early stopping\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4753)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4753)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4752)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4752)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4754)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4754)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4755)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4755)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4751)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4751)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4757)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4757)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4756)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4756)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4750)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=4750)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.982\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 578.93s of the 878.16s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=4750)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4750)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4750)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4750)\u001b[0m This will raise in a future version.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4750)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.982\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 577.83s of the 877.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.982\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 577.14s of the 876.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t9.75s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 565.20s of the 864.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 564.48s of the 863.70s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 563.81s of the 863.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 560.73s of the 859.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=5926, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=5926, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 555.45s of the 854.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_ray_fit pid=6252)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=6252)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=6252)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6252)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=6252)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=6252)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6252)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=6256)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6256)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6255)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6255)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6258)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6258)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6254)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6254)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6253)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6253)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6257)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6257)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6259)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=6259)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t2.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 550.22s of the 849.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t8.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 538.99s of the 838.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=6259)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6259)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6259)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6259)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=6259)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=7018, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=7018, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 534.04s of the 833.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\u001b[36m(_ray_fit pid=7350)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7350)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7350)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=7350)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=7350)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=7350)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=7350)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7349)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=7346)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7346)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7347)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7347)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7348)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7348)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7352)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7352)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7351)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7351)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7353)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7353)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 530.00s of the 829.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=7668)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_ray_fit pid=7353)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7353)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7353)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7353)\u001b[0m This will raise in a future version.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7353)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t8.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 519.11s of the 818.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.982\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t22.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 494.27s of the 793.50s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=7672)\u001b[0m No improvement since epoch 18: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8504)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=8504)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=8504)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8504)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=8504)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=8504)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8504)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=8507)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8507)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8509)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8509)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8511)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8511)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8508)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8508)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8506)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8506)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8510)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8510)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8505)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=8505)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9459\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 490.42s of the 789.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=8829, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=8829, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=8505)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8505)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8505)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8505)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=8505)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 485.12s of the 784.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.65s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 481.16s of the 780.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.982\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 480.27s of the 779.49s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t4.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 473.96s of the 773.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=9934)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t6.13s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 465.58s of the 764.80s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t28.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 434.35s of the 733.58s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=9935)\u001b[0m No improvement since epoch 8: early stopping\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9775\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 432.86s of the 732.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_ray_fit pid=10779)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=10779)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=10779)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10779)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=10779)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=10779)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10779)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=10782)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10782)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10783)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10783)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10777)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10777)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10778)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10778)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10780)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10780)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10781)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10781)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10776)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10776)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9775\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 428.94s of the 728.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=11099)\u001b[0m No improvement since epoch 5: early stopping\n",
      "\u001b[36m(_ray_fit pid=10776)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10776)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10776)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10776)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10776)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.973\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t5.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 421.38s of the 720.60s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 417.28s of the 716.50s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r30_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=11800, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=11800, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=11097)\u001b[0m No improvement since epoch 9: early stopping\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 411.83s of the 711.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001b[36m(_ray_fit pid=12144)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=12144)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=12144)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12144)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=12144)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=12144)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12144)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=12145)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12145)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12150)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12150)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12146)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12146)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12148)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12148)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12147)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12147)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12151)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12151)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12149)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=12149)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 407.74s of the 706.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r86_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=12469, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=12469, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=12149)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=12149)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=12149)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=12149)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=12149)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=11803, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=11807, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 402.46s of the 701.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t4.75s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 395.45s of the 694.67s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=13239)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t5.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 388.14s of the 687.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 383.96s of the 683.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9685\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 383.14s of the 682.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_ray_fit pid=13242)\u001b[0m No improvement since epoch 4: early stopping\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t5.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 375.32s of the 674.54s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=14404)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t6.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 366.23s of the 665.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r14_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14787, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14787, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=14401)\u001b[0m No improvement since epoch 17: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 361.02s of the 660.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_ray_fit pid=15108)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=15108)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=15108)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15108)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=15108)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=15108)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15108)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=15113)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15113)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15107)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15107)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15111)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15111)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15112)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15112)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15109)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15109)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15106)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15106)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15110)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=15110)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 356.80s of the 656.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=15427)\u001b[0m No improvement since epoch 3: early stopping\n",
      "\u001b[36m(_ray_fit pid=15110)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=15110)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=15110)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=15110)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=15110)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=15426)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.982\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t7.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 346.97s of the 646.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t11.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 333.11s of the 632.33s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=15428)\u001b[0m No improvement since epoch 10: early stopping\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=16258)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_ray_fit pid=16251)\u001b[0m No improvement since epoch 8: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t6.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 324.23s of the 623.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=16644)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=16644)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=16644)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16644)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=16644)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=16644)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16644)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=16640)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16640)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16645)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16645)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16641)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16641)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16638)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16638)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16639)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16639)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16642)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16642)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16643)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=16643)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9775\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 319.48s of the 618.71s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=16257)\u001b[0m No improvement since epoch 23: early stopping\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9775\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 318.20s of the 617.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t15.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 300.01s of the 599.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=16643)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=16643)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=16643)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=16643)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=16643)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=17423)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t4.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 292.90s of the 592.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r41_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=17801, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17801, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=17422)\u001b[0m No improvement since epoch 7: early stopping\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 287.20s of the 586.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 282.93s of the 582.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_ray_fit pid=18448)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=18448)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=18448)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18448)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=18448)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=18448)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18448)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=18446)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18446)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18447)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18447)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18451)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18451)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18449)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18449)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18445)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18445)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18450)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18450)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18444)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=18444)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t2.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 278.29s of the 577.52s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r158_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18766, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18766, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=18444)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=18444)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=18444)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=18444)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=18444)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r86_BAG_L1 ... Training model for up to 272.77s of the 572.00s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t22.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 247.84s of the 547.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=19540)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t7.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 238.47s of the 537.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r197_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=19926, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=19926, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=19546)\u001b[0m No improvement since epoch 16: early stopping\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r49_BAG_L1 ... Training model for up to 233.16s of the 532.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t4.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: ExtraTrees_r49_BAG_L1 ... Training model for up to 226.82s of the 526.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r143_BAG_L1 ... Training model for up to 225.63s of the 524.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_ray_fit pid=20713)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=20713)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=20713)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20713)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=20713)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=20713)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20713)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=20707)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20707)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20710)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20710)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20709)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20709)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20708)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20708)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20714)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20714)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20711)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20711)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20712)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=20712)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9775\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: RandomForest_r127_BAG_L1 ... Training model for up to 221.62s of the 520.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9369\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 219.74s of the 518.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=21048)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_ray_fit pid=20712)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=20712)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=20712)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=20712)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=20712)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t7.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: RandomForest_r34_BAG_L1 ... Training model for up to 209.93s of the 509.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.8784\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r94_BAG_L1 ... Training model for up to 209.06s of the 508.28s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=21459)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21459)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21046)\u001b[0m No improvement since epoch 15: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=21459)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=21459)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=21459)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=21459)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=21459)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=21455)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=21455)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=21455)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21455)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=21455)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=21455)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21455)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=21456)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21456)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21453)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21453)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21457)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21457)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21454)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21454)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21460)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21460)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21458)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=21458)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.973\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 205.35s of the 504.58s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r143_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=21774, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21774, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=21458)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=21458)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=21458)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=21458)\u001b[0m This will raise in a future version.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=21458)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r128_BAG_L1 ... Training model for up to 199.72s of the 498.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t27.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 169.94s of the 469.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=22540)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t5.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 161.82s of the 461.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r31_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22925, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22925, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=22542)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: ExtraTrees_r4_BAG_L1 ... Training model for up to 156.23s of the 455.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9054\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 155.47s of the 454.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=23272)\u001b[0m No improvement since epoch 6: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.964\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t6.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 146.96s of the 446.18s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=23655)\u001b[0m No improvement since epoch 2: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t7.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r30_BAG_L1 ... Training model for up to 137.17s of the 436.40s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\u001b[36m(_ray_fit pid=24042)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=24042)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=24042)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24042)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=24042)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=24042)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24042)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=24041)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24041)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24040)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24040)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24039)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24039)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24037)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24037)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24038)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24038)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24035)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24035)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24036)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=24036)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.973\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_r49_BAG_L1 ... Training model for up to 133.07s of the 432.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=23649)\u001b[0m No improvement since epoch 26: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.43s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r5_BAG_L1 ... Training model for up to 128.94s of the 428.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=24036)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=24036)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=24036)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=24036)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=24036)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t3.97s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 122.38s of the 421.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r87_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=25117, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25117, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 117.21s of the 416.43s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r71_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=25447, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25447, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r143_BAG_L1 ... Training model for up to 112.12s of the 411.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t15.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: ExtraTrees_r178_BAG_L1 ... Training model for up to 94.27s of the 393.49s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.973\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: RandomForest_r166_BAG_L1 ... Training model for up to 93.02s of the 392.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_r31_BAG_L1 ... Training model for up to 91.43s of the 390.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 87.40s of the 386.63s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r185_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=26593, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=26593, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 82.13s of the 381.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9775\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t4.54s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r60_BAG_L1 ... Training model for up to 75.17s of the 374.40s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t6.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: RandomForest_r15_BAG_L1 ... Training model for up to 65.99s of the 365.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.964\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r135_BAG_L1 ... Training model for up to 64.49s of the 363.72s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_ray_fit pid=27790)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=27790)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=27790)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27790)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=27790)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=27790)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27790)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=27791)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27791)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27786)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27786)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27785)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27785)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27789)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27789)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27787)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27787)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27788)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27788)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27784)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=27784)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.982\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.52s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_r22_BAG_L1 ... Training model for up to 60.72s of the 359.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r69_BAG_L1 ... Training model for up to 56.98s of the 356.20s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t4.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r6_BAG_L1 ... Training model for up to 49.86s of the 349.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=27784)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=27784)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=27784)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=27784)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=27784)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t4.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r138_BAG_L1 ... Training model for up to 42.49s of the 341.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=29239)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t5.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r121_BAG_L1 ... Training model for up to 34.80s of the 334.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_ray_fit pid=29619)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=29619)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=29619)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29619)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=29619)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=29619)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29619)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=29621)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29621)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29623)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29623)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29625)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29625)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29624)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29624)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29618)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29618)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29622)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29622)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29620)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=29620)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t2.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r172_BAG_L1 ... Training model for up to 29.77s of the 328.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=29240)\u001b[0m No improvement since epoch 18: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29620)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29620)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29620)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29620)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29620)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29939)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_ray_fit pid=29937)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t6.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r180_BAG_L1 ... Training model for up to 20.94s of the 320.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=30328)\u001b[0m \tRan out of time, early stopping on iteration 323.\n",
      "\u001b[36m(_ray_fit pid=29938)\u001b[0m No improvement since epoch 2: early stopping\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t17.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r76_BAG_L1 ... Training model for up to 1.19s of the 300.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r76_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=30774, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=30774, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=30334)\u001b[0m \tRan out of time, early stopping on iteration 309.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=26586, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 295.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 295.15s of the 294.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=31112)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t5.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 287.06s of the 286.91s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\u001b[36m(_ray_fit pid=31495)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=31495)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=31495)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31495)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=31495)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=31495)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31495)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=31496)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31496)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31499)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31499)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31500)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31500)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31497)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31497)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31501)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31501)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31498)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31498)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31494)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31494)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t2.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 282.21s of the 282.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\u001b[36m(_ray_fit pid=31115)\u001b[0m No improvement since epoch 1: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=31816)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31816)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31815)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31815)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31812)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31812)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31811)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31811)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31810)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31810)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31810)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=31810)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=31810)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=31810)\u001b[0m This will raise in a future version.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=31810)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=31813)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31813)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31814)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31814)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31817)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=31817)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 277.70s of the 277.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 276.72s of the 276.56s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.58s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 276.01s of the 275.86s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.43%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t11.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 261.91s of the 261.75s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=31817)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=31817)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=31817)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=31817)\u001b[0m This will raise in a future version.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=31817)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 260.98s of the 260.83s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 260.29s of the 260.13s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.43%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 257.11s of the 256.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=511, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=511, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 251.79s of the 251.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.87%)\n",
      "\u001b[36m(_ray_fit pid=853)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=853)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=853)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=853)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=853)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=853)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=853)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=852)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=852)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=856)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=856)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=854)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=854)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=851)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=851)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=855)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=855)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=857)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=857)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=850)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=850)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.982\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t3.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 246.31s of the 246.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.46%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t12.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 231.40s of the 231.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=850)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=850)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=850)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=850)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=850)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1637, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1637, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=518, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 226.16s of the 226.00s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\u001b[36m(_ray_fit pid=1967)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=1967)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=1967)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1967)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=1967)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=1967)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1967)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=1966)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1966)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1968)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1968)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1971)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1971)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1973)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1973)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1972)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1972)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1970)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1970)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1969)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1969)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 221.97s of the 221.81s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=2309)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_ray_fit pid=1969)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1969)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1969)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1969)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1969)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t6.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 212.41s of the 212.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.92%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t30.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 178.82s of the 178.67s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=2305)\u001b[0m No improvement since epoch 4: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_ray_fit pid=3158)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=3158)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=3158)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3158)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=3158)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=3158)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3158)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=3156)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3156)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3160)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3160)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3162)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3162)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3157)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3157)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3161)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3161)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3159)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3159)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3163)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3163)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 175.01s of the 174.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r22_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=3586, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=3586, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=3163)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3163)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3163)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3163)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3163)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 169.40s of the 169.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.49%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 165.55s of the 165.40s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 164.52s of the 164.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.0\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t4.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 157.96s of the 157.80s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=4886)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t5.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 149.56s of the 149.40s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.91%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t34.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 111.72s of the 111.56s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=4885)\u001b[0m No improvement since epoch 4: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9865\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 110.18s of the 110.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.84%)\n",
      "\u001b[36m(_ray_fit pid=5729)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=5729)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=5729)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5729)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=5729)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=5729)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5729)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=5731)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5731)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5733)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5733)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5734)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5734)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5736)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5736)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5730)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5730)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5732)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5732)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5735)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=5735)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 106.11s of the 105.95s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=6047)\u001b[0m No improvement since epoch 4: early stopping\n",
      "\u001b[36m(_ray_fit pid=5735)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5735)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5735)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5735)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=5735)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t4.75s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 98.55s of the 98.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.49%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 94.41s of the 94.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r30_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=6749, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=6749, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=6051)\u001b[0m No improvement since epoch 3: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=3541, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r130_BAG_L2 ... Training model for up to 89.00s of the 88.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.60%)\n",
      "\u001b[36m(_ray_fit pid=7079)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=7079)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=7079)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7079)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=7079)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=7079)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7079)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=7075)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7075)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7076)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7076)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7077)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7077)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7074)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7074)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7078)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7078)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7081)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7081)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7080)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=7080)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.6s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 85.14s of the 84.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r86_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=7399, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=7399, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=7080)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7080)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7080)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7080)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=7080)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r50_BAG_L2 ... Training model for up to 79.43s of the 79.27s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t5.65s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r11_BAG_L2 ... Training model for up to 71.49s of the 71.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=8190)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t4.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: XGBoost_r194_BAG_L2 ... Training model for up to 64.23s of the 64.07s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.98%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.58s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: ExtraTrees_r172_BAG_L2 ... Training model for up to 59.77s of the 59.62s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r69_BAG_L2 ... Training model for up to 59.01s of the 58.86s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\u001b[36m(_ray_fit pid=8193)\u001b[0m No improvement since epoch 1: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t6.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r103_BAG_L2 ... Training model for up to 49.85s of the 49.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=9350)\u001b[0m No improvement since epoch 0: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.0\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t6.3s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetTorch_r14_BAG_L2 ... Training model for up to 40.97s of the 40.81s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r14_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=9739, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=9739, ip=169.255.255.2)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_ray_fit pid=9353)\u001b[0m No improvement since epoch 10: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: LightGBM_r161_BAG_L2 ... Training model for up to 35.19s of the 35.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.69%)\n",
      "\u001b[36m(_ray_fit pid=10078)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_ray_fit pid=10078)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_ray_fit pid=10078)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10078)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_ray_fit pid=10078)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_ray_fit pid=10078)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10078)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_ray_fit pid=10080)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10080)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10079)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10079)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10076)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10076)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10083)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10083)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10077)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10077)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10081)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10081)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10082)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=10082)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.991\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t2.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: NeuralNetFastAI_r143_BAG_L2 ... Training model for up to 30.86s of the 30.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=10398)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_ray_fit pid=10082)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10082)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10082)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10082)\u001b[0m This will raise in a future version.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10082)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10396)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.9955\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t6.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: CatBoost_r70_BAG_L2 ... Training model for up to 21.87s of the 21.72s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.48%)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.0\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t14.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=10397)\u001b[0m No improvement since epoch 4: early stopping\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 4.11s of remaining time.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \tEnsemble Weights: {'CatBoost_r137_BAG_L2': 1.0}\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t1.0\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m AutoGluon training complete, total runtime = 893.31s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 149.7 rows/s (28 batch size)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/sagemaker-user/AUDIO SENTIMENT ANALYSIS - NUMERIC EMBEDDING/AutogluonModels/ag-20241226_075449/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m /opt/conda/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m \n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=3652)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0                LightGBM_BAG_L1       1.000000   0.981982    accuracy        0.007972       0.007508   1.682114                 0.007972                0.007508           1.682114            1       True          5\n",
      "1           LightGBM_r188_BAG_L1       1.000000   0.977477    accuracy        0.009970       0.008377   1.726074                 0.009970                0.008377           1.726074            1       True         24\n",
      "2           LightGBM_r131_BAG_L1       1.000000   0.986486    accuracy        0.011824       0.010127   1.744725                 0.011824                0.010127           1.744725            1       True         14\n",
      "3           LightGBM_r135_BAG_L1       1.000000   0.981982    accuracy        0.013243       0.009033   1.520102                 0.013243                0.009033           1.520102            1       True         68\n",
      "4           CatBoost_r143_BAG_L1       1.000000   0.990991    accuracy        0.013299       0.010290  15.569630                 0.013299                0.010290          15.569630            1       True         61\n",
      "5           LightGBM_r121_BAG_L1       1.000000   0.986486    accuracy        0.014301       0.009795   2.116071                 0.014301                0.009795           2.116071            1       True         73\n",
      "6           CatBoost_r177_BAG_L1       1.000000   0.986486    accuracy        0.014438       0.009792   8.835252                 0.014438                0.009792           8.835252            1       True         13\n",
      "7           CatBoost_r167_BAG_L1       1.000000   0.990991    accuracy        0.014881       0.009403  15.951994                 0.014881                0.009403          15.951994            1       True         40\n",
      "8            CatBoost_r86_BAG_L1       1.000000   0.986486    accuracy        0.015004       0.009595  22.676149                 0.015004                0.009595          22.676149            1       True         44\n",
      "9             CatBoost_r6_BAG_L1       1.000000   0.986486    accuracy        0.015026       0.009504   4.382411                 0.015026                0.009504           4.382411            1       True         71\n",
      "10            CatBoost_r9_BAG_L1       1.000000   0.981982    accuracy        0.015163       0.008985  22.494154                 0.015163                0.008985          22.494154            1       True         16\n",
      "11           CatBoost_r69_BAG_L1       1.000000   0.986486    accuracy        0.015258       0.011894   5.591243                 0.015258                0.011894           5.591243            1       True         32\n",
      "12           CatBoost_r13_BAG_L1       1.000000   0.990991    accuracy        0.015341       0.010661  28.560818                 0.015341                0.010661          28.560818            1       True         22\n",
      "13            CatBoost_r5_BAG_L1       1.000000   0.986486    accuracy        0.015375       0.011096   3.972038                 0.015375                0.011096           3.972038            1       True         60\n",
      "14           CatBoost_r49_BAG_L1       1.000000   0.986486    accuracy        0.015538       0.010159   4.098886                 0.015538                0.010159           4.098886            1       True         46\n",
      "15          LightGBM_r161_BAG_L1       1.000000   0.986486    accuracy        0.015574       0.009897   1.877461                 0.015574                0.009897           1.877461            1       True         34\n",
      "16           CatBoost_r50_BAG_L1       1.000000   0.986486    accuracy        0.015588       0.009139   4.751591                 0.015588                0.009139           4.751591            1       True         28\n",
      "17          CatBoost_r137_BAG_L1       1.000000   0.986486    accuracy        0.015719       0.012341   4.097865                 0.015719                0.012341           4.097865            1       True         20\n",
      "18           CatBoost_r60_BAG_L1       1.000000   0.986486    accuracy        0.015741       0.010533   6.272849                 0.015741                0.010533           6.272849            1       True         66\n",
      "19          CatBoost_r180_BAG_L1       1.000000   0.990991    accuracy        0.016256       0.010301  17.004954                 0.016256                0.010301          17.004954            1       True         75\n",
      "20          CatBoost_r128_BAG_L1       1.000000   0.986486    accuracy        0.018596       0.009149  27.492510                 0.018596                0.009149          27.492510            1       True         53\n",
      "21          LightGBM_r143_BAG_L1       1.000000   0.977477    accuracy        0.020551       0.009042   1.791254                 0.020551                0.009042           1.791254            1       True         48\n",
      "22           CatBoost_r70_BAG_L1       1.000000   0.986486    accuracy        0.021878       0.010049  11.404975                 0.021878                0.010049          11.404975            1       True         36\n",
      "23           LightGBM_r30_BAG_L1       1.000000   0.972973    accuracy        0.022557       0.012020   1.706396                 0.022557                0.012020           1.706396            1       True         58\n",
      "24           LightGBM_r94_BAG_L1       1.000000   0.972973    accuracy        0.022813       0.009604   1.461392                 0.022813                0.009604           1.461392            1       True         52\n",
      "25          LightGBM_r196_BAG_L1       1.000000   0.977477    accuracy        0.026093       0.011868   1.939784                 0.026093                0.011868           1.939784            1       True         38\n",
      "26          LightGBMLarge_BAG_L1       1.000000   0.986486    accuracy        0.028927       0.011073   2.731898                 0.028927                0.011073           2.731898            1       True         12\n",
      "27       RandomForestEntr_BAG_L1       1.000000   0.981982    accuracy        0.041122       0.090282   0.588402                 0.041122                0.090282           0.588402            1       True          7\n",
      "28      RandomForest_r166_BAG_L1       1.000000   0.986486    accuracy        0.041195       0.089911   1.480238                 0.041195                0.089911           1.480238            1       True         63\n",
      "29        ExtraTrees_r178_BAG_L1       1.000000   0.972973    accuracy        0.041788       0.091155   1.141421                 0.041788                0.091155           1.141421            1       True         62\n",
      "30        ExtraTrees_r172_BAG_L1       1.000000   0.968468    accuracy        0.041918       0.091921   0.717823                 0.041918                0.091921           0.717823            1       True         31\n",
      "31         ExtraTrees_r42_BAG_L1       1.000000   0.981982    accuracy        0.042532       0.090669   0.790509                 0.042532                0.090669           0.790509            1       True         19\n",
      "32       RandomForestGini_BAG_L1       1.000000   0.981982    accuracy        0.042974       0.091195   0.992615                 0.042974                0.091195           0.992615            1       True          6\n",
      "33          ExtraTrees_r4_BAG_L1       1.000000   0.905405    accuracy        0.043644       0.105118   0.637822                 0.043644                0.105118           0.637822            1       True         55\n",
      "34         ExtraTreesEntr_BAG_L1       1.000000   0.990991    accuracy        0.052194       0.090913   0.570265                 0.052194                0.090913           0.570265            1       True         10\n",
      "35         ExtraTrees_r49_BAG_L1       1.000000   0.986486    accuracy        0.052840       0.091418   1.084279                 0.052840                0.091418           1.084279            1       True         47\n",
      "36         ExtraTreesGini_BAG_L1       1.000000   0.986486    accuracy        0.055861       0.091025   0.611007                 0.055861                0.091025           0.611007            1       True          9\n",
      "37   NeuralNetFastAI_r172_BAG_L1       1.000000   0.995495    accuracy        0.068167       0.078346   6.202274                 0.068167                0.078346           6.202274            1       True         74\n",
      "38    NeuralNetFastAI_r88_BAG_L1       1.000000   0.995495    accuracy        0.068807       0.074700   7.094073                 0.068807                0.074700           7.094073            1       True         57\n",
      "39   NeuralNetFastAI_r111_BAG_L1       1.000000   0.986486    accuracy        0.073513       0.074318   5.824380                 0.073513                0.074318           5.824380            1       True         54\n",
      "40   NeuralNetFastAI_r102_BAG_L1       1.000000   0.995495    accuracy        0.074786       0.077304   6.129743                 0.074786                0.077304           6.129743            1       True         21\n",
      "41    NeuralNetFastAI_r69_BAG_L1       1.000000   0.986486    accuracy        0.075931       0.077809   4.564071                 0.075931                0.077809           4.564071            1       True         70\n",
      "42   NeuralNetFastAI_r103_BAG_L1       1.000000   0.995495    accuracy        0.076086       0.084558   6.823350                 0.076086                0.084558           6.823350            1       True         33\n",
      "43   NeuralNetFastAI_r160_BAG_L1       1.000000   0.977477    accuracy        0.076573       0.075712   4.538655                 0.076573                0.075712           4.538655            1       True         65\n",
      "44   NeuralNetFastAI_r138_BAG_L1       1.000000   0.986486    accuracy        0.076743       0.083284   5.233336                 0.076743                0.083284           5.233336            1       True         72\n",
      "45    NeuralNetFastAI_r95_BAG_L1       1.000000   0.986486    accuracy        0.077079       0.076972   4.864381                 0.077079                0.076972           4.864381            1       True         41\n",
      "46   NeuralNetFastAI_r143_BAG_L1       1.000000   0.981982    accuracy        0.077376       0.082322   7.168415                 0.077376                0.082322           7.168415            1       True         35\n",
      "47   NeuralNetFastAI_r145_BAG_L1       1.000000   0.972973    accuracy        0.077566       0.083354   5.027277                 0.077566                0.083354           5.027277            1       True         25\n",
      "48    NeuralNetFastAI_r11_BAG_L1       1.000000   0.990991    accuracy        0.078297       0.079019   5.044999                 0.078297                0.079019           5.044999            1       True         29\n",
      "49            XGBoost_r89_BAG_L1       1.000000   0.990991    accuracy        0.081551       0.026532   1.070558                 0.081551                0.026532           1.070558            1       True         26\n",
      "50            XGBoost_r22_BAG_L1       1.000000   0.995495    accuracy        0.083058       0.026686   0.938066                 0.083058                0.026686           0.938066            1       True         69\n",
      "51   NeuralNetFastAI_r191_BAG_L1       1.000000   0.995495    accuracy        0.083290       0.092941   8.113258                 0.083290                0.092941           8.113258            1       True         15\n",
      "52            XGBoost_r49_BAG_L1       1.000000   0.995495    accuracy        0.084310       0.025816   1.431098                 0.084310                0.025816           1.431098            1       True         59\n",
      "53            XGBoost_r33_BAG_L1       1.000000   0.990991    accuracy        0.084713       0.026095   1.646675                 0.084713                0.026095           1.646675            1       True         18\n",
      "54   NeuralNetFastAI_r134_BAG_L1       1.000000   0.995495    accuracy        0.086832       0.086645   7.571923                 0.086832                0.086645           7.571923            1       True         50\n",
      "55           XGBoost_r194_BAG_L1       1.000000   0.986486    accuracy        0.087887       0.029794   1.306293                 0.087887                0.029794           1.306293            1       True         30\n",
      "56    NeuralNetFastAI_r37_BAG_L1       1.000000   0.995495    accuracy        0.088837       0.081846   7.047362                 0.088837                0.081846           7.047362            1       True         45\n",
      "57   NeuralNetFastAI_r156_BAG_L1       1.000000   0.995495    accuracy        0.088846       0.077867   6.616051                 0.088846                0.077867           6.616051            1       True         37\n",
      "58            XGBoost_r31_BAG_L1       1.000000   0.990991    accuracy        0.092252       0.028604   1.787889                 0.092252                0.028604           1.787889            1       True         64\n",
      "59            XGBoost_r98_BAG_L1       1.000000   0.990991    accuracy        0.094909       0.028356   1.961123                 0.094909                0.028356           1.961123            1       True         42\n",
      "60               CatBoost_BAG_L1       1.000000   0.986486    accuracy        0.291013       0.011853   9.749623                 0.291013                0.011853           9.749623            1       True          8\n",
      "61        NeuralNetFastAI_BAG_L1       1.000000   0.995495    accuracy        0.438733       0.082329   6.093975                 0.438733                0.082329           6.093975            1       True          3\n",
      "62           WeightedEnsemble_L2       1.000000   0.995495    accuracy        0.440074       0.083171   6.174864                 0.001341                0.000841           0.080889            2       True         76\n",
      "63             LightGBMXT_BAG_L1       1.000000   0.986486    accuracy        0.612611       0.009060   1.760915                 0.612611                0.009060           1.760915            1       True          4\n",
      "64               LightGBM_BAG_L2       1.000000   0.990991    accuracy        0.700809       0.323033  41.461413                 0.006723                0.012712           1.734796            2       True         79\n",
      "65          LightGBM_r131_BAG_L2       1.000000   0.990991    accuracy        0.701266       0.325922  41.577638                 0.007180                0.015601           1.851020            2       True         88\n",
      "66          LightGBMLarge_BAG_L2       1.000000   0.981982    accuracy        0.701597       0.324426  42.751724                 0.007511                0.014104           3.025106            2       True         86\n",
      "67          LightGBM_r130_BAG_L2       1.000000   0.990991    accuracy        0.701968       0.324943  41.321705                 0.007882                0.014621           1.595087            2       True        101\n",
      "68           LightGBM_r96_BAG_L2       1.000000   0.995495    accuracy        0.702188       0.324580  41.170217                 0.008102                0.014259           1.443599            2       True         91\n",
      "69          LightGBM_r161_BAG_L2       1.000000   0.990991    accuracy        0.702461       0.326107  41.783033                 0.008375                0.015786           2.056416            2       True        108\n",
      "70          LightGBM_r188_BAG_L2       1.000000   0.995495    accuracy        0.702997       0.325687  41.491012                 0.008911                0.015365           1.764395            2       True         98\n",
      "71             LightGBMXT_BAG_L2       1.000000   0.995495    accuracy        0.704442       0.326078  41.756540                 0.010356                0.015756           2.029922            2       True         78\n",
      "72          CatBoost_r177_BAG_L2       1.000000   0.995495    accuracy        0.711802       0.344616  51.992047                 0.017716                0.034295          12.265430            2       True         87\n",
      "73           CatBoost_r13_BAG_L2       1.000000   0.995495    accuracy        0.711961       0.341698  74.429638                 0.017875                0.031376          34.703021            2       True         96\n",
      "74          CatBoost_r137_BAG_L2       1.000000   1.000000    accuracy        0.712263       0.346209  43.996302                 0.018177                0.035887           4.269684            2       True         94\n",
      "75           CatBoost_r70_BAG_L2       1.000000   1.000000    accuracy        0.712404       0.342337  54.222840                 0.018318                0.032016          14.496222            2       True        110\n",
      "76            CatBoost_r9_BAG_L2       1.000000   0.995495    accuracy        0.712673       0.342164  70.421642                 0.018587                0.031843          30.695025            2       True         90\n",
      "77           CatBoost_r50_BAG_L2       1.000000   0.995495    accuracy        0.712947       0.345156  45.381414                 0.018861                0.034835           5.654797            2       True        102\n",
      "78           WeightedEnsemble_L3       1.000000   1.000000    accuracy        0.713608       0.347062  44.076349                 0.001345                0.000853           0.080047            3       True        111\n",
      "79               CatBoost_BAG_L2       1.000000   0.995495    accuracy        0.714070       0.342991  51.579722                 0.019984                0.032670          11.853104            2       True         82\n",
      "80           CatBoost_r69_BAG_L2       1.000000   0.990991    accuracy        0.714238       0.349324  46.615629                 0.020152                0.039003           6.889012            2       True        106\n",
      "81         ExtraTreesEntr_BAG_L2       1.000000   0.990991    accuracy        0.735342       0.402871  40.296847                 0.041255                0.092550           0.570229            2       True         84\n",
      "82         ExtraTrees_r42_BAG_L2       1.000000   0.986486    accuracy        0.735661       0.401716  40.627759                 0.041575                0.091395           0.901141            2       True         93\n",
      "83         ExtraTreesGini_BAG_L2       1.000000   0.990991    accuracy        0.736366       0.401281  40.524526                 0.042279                0.090959           0.797908            2       True         83\n",
      "84       RandomForestGini_BAG_L2       1.000000   0.986486    accuracy        0.736901       0.402023  40.584494                 0.042814                0.091702           0.857877            2       True         80\n",
      "85      RandomForest_r195_BAG_L2       1.000000   0.986486    accuracy        0.737250       0.401772  41.139070                 0.043164                0.091450           1.412452            2       True         97\n",
      "86        ExtraTrees_r172_BAG_L2       1.000000   0.990991    accuracy        0.737928       0.401433  40.363429                 0.043842                0.091111           0.636812            2       True        105\n",
      "87       RandomForestEntr_BAG_L2       1.000000   0.986486    accuracy        0.738884       0.400430  40.310227                 0.044798                0.090109           0.583610            2       True         81\n",
      "88   NeuralNetFastAI_r102_BAG_L2       1.000000   0.995495    accuracy        0.771811       0.400695  45.489971                 0.077725                0.090374           5.763353            2       True         95\n",
      "89        NeuralNetFastAI_BAG_L2       1.000000   0.995495    accuracy        0.772332       0.401061  45.492367                 0.078246                0.090740           5.765749            2       True         77\n",
      "90   NeuralNetFastAI_r143_BAG_L2       1.000000   0.995495    accuracy        0.774081       0.407118  45.992330                 0.079995                0.096796           6.265712            2       True        109\n",
      "91   NeuralNetFastAI_r103_BAG_L2       1.000000   1.000000    accuracy        0.777856       0.406771  46.031461                 0.083770                0.096450           6.304843            2       True        107\n",
      "92   NeuralNetFastAI_r191_BAG_L2       1.000000   0.995495    accuracy        0.779889       0.411813  46.438641                 0.085803                0.101492           6.712023            2       True         89\n",
      "93    NeuralNetFastAI_r11_BAG_L2       1.000000   0.995495    accuracy        0.780513       0.411675  44.521443                 0.086426                0.101354           4.794825            2       True        103\n",
      "94   NeuralNetFastAI_r145_BAG_L2       1.000000   0.995495    accuracy        0.781519       0.398304  44.475332                 0.087433                0.087982           4.748714            2       True         99\n",
      "95            XGBoost_r33_BAG_L2       1.000000   0.995495    accuracy        0.786609       0.341818  41.172605                 0.092523                0.031496           1.445988            2       True         92\n",
      "96                XGBoost_BAG_L2       1.000000   0.995495    accuracy        0.795810       0.344879  40.636233                 0.101724                0.034558           0.909616            2       True         85\n",
      "97            XGBoost_r89_BAG_L2       1.000000   0.995495    accuracy        0.797373       0.342940  40.621228                 0.103287                0.032619           0.894611            2       True        100\n",
      "98           XGBoost_r194_BAG_L2       1.000000   0.995495    accuracy        0.810751       0.360632  41.304301                 0.116665                0.050311           1.577683            2       True        104\n",
      "99           LightGBM_r15_BAG_L1       0.964286   0.990991    accuracy        0.008680       0.007295   2.010811                 0.008680                0.007295           2.010811            1       True         43\n",
      "100          LightGBM_r96_BAG_L1       0.964286   0.945946    accuracy        0.011985       0.007981   1.525374                 0.011985                0.007981           1.525374            1       True         17\n",
      "101         LightGBM_r130_BAG_L1       0.964286   0.990991    accuracy        0.012711       0.009320   1.586819                 0.012711                0.009320           1.586819            1       True         27\n",
      "102        KNeighborsDist_BAG_L1       0.964286   0.869369    accuracy        0.049602       0.001372   0.003405                 0.049602                0.001372           0.003405            1       True          2\n",
      "103     RandomForest_r195_BAG_L1       0.928571   0.977477    accuracy        0.041859       0.091251   1.381809                 0.041859                0.091251           1.381809            1       True         23\n",
      "104        KNeighborsUnif_BAG_L1       0.928571   0.842342    accuracy        0.042784       0.027370   0.004522                 0.042784                0.027370           0.004522            1       True          1\n",
      "105      RandomForest_r15_BAG_L1       0.928571   0.963964    accuracy        0.042804       0.088707   1.390711                 0.042804                0.088707           1.390711            1       True         67\n",
      "106      RandomForest_r39_BAG_L1       0.928571   0.977477    accuracy        0.042829       0.090861   1.175312                 0.042829                0.090861           1.175312            1       True         39\n",
      "107      RandomForest_r34_BAG_L1       0.928571   0.878378    accuracy        0.043112       0.091514   0.756974                 0.043112                0.091514           0.756974            1       True         51\n",
      "108   NeuralNetFastAI_r65_BAG_L1       0.928571   0.963964    accuracy        0.067884       0.074699   6.241040                 0.067884                0.074699           6.241040            1       True         56\n",
      "109     RandomForest_r127_BAG_L1       0.892857   0.936937    accuracy        0.043162       0.102075   1.758427                 0.043162                0.102075           1.758427            1       True         49\n",
      "110               XGBoost_BAG_L1       0.892857   0.986486    accuracy        0.092027       0.027071   0.859284                 0.092027                0.027071           0.859284            1       True         11\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t904s\t = DyStack   runtime |\t2696s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 2696s\n",
      "AutoGluon will save models to \"/home/sagemaker-user/AUDIO SENTIMENT ANALYSIS - NUMERIC EMBEDDING/AutogluonModels/ag-20241226_075449\"\n",
      "Train Data Rows:    250\n",
      "Train Data Columns: 27\n",
      "Label Column:       Class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22116.10 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Filename']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Filename']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 26 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 26 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t26 features in original data used to generate 26 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2696.23s of the 2696.21s of remaining time.\n",
      "\t0.856\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2694.36s of the 2694.35s of remaining time.\n",
      "\t0.908\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2694.33s of the 2694.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t6.22s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2685.78s of the 2685.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.98\t = Validation score   (accuracy)\n",
      "\t1.82s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2680.98s of the 2680.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.976\t = Validation score   (accuracy)\n",
      "\t1.73s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2676.32s of the 2676.31s of remaining time.\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2675.32s of the 2675.31s of remaining time.\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2674.62s of the 2674.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.98\t = Validation score   (accuracy)\n",
      "\t9.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2662.78s of the 2662.77s of remaining time.\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2662.07s of the 2662.06s of remaining time.\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2661.38s of the 2661.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.98\t = Validation score   (accuracy)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2658.04s of the 2658.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=13559, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=13559, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2652.46s of the 2652.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t2.87s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 2647.24s of the 2647.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "2024-12-26 08:10:42,590\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:10:42,591\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:10:42,593\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:10:42,594\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:10:42,594\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:10:42,595\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:10:42,596\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.98\t = Validation score   (accuracy)\n",
      "\t10.28s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 2634.16s of the 2634.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14775, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14775, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 2628.73s of the 2628.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.98\t = Validation score   (accuracy)\n",
      "\t1.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 2624.41s of the 2624.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "2024-12-26 08:11:06,600\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:11:06,601\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:11:06,603\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:11:06,604\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:11:06,605\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:11:06,606\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t7.54s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 2614.12s of the 2614.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t26.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 2585.35s of the 2585.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t0.968\t = Validation score   (accuracy)\n",
      "\t1.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 2581.37s of the 2581.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=16769, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16769, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 2575.65s of the 2575.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t1.95s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 2571.30s of the 2571.29s of remaining time.\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 2570.41s of the 2570.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "2024-12-26 08:11:59,624\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:11:59,626\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:11:59,627\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:11:59,628\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:11:59,629\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:11:59,630\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:11:59,631\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.98\t = Validation score   (accuracy)\n",
      "\t4.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 2563.69s of the 2563.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t6.08s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 2555.18s of the 2555.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t33.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 2519.02s of the 2519.01s of remaining time.\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 2517.51s of the 2517.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 2513.41s of the 2513.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t4.99s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 2505.48s of the 2505.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 2501.24s of the 2501.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r30_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=20060, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20060, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 2495.52s of the 2495.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.972\t = Validation score   (accuracy)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 2491.53s of the 2491.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "2024-12-26 08:13:19,669\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=20063, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2024-12-26 08:13:19,671\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:13:19,673\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:13:19,675\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:13:19,677\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:13:19,679\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:13:19,681\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused NeuralNetTorch_r86_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=20796, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20796, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 2485.61s of the 2485.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "2024-12-26 08:13:29,673\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:13:29,676\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:13:29,677\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:13:29,679\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:13:29,681\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:13:29,682\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:13:29,683\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.972\t = Validation score   (accuracy)\n",
      "\t5.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 2478.23s of the 2478.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t5.06s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 2470.78s of the 2470.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t1.74s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 2466.03s of the 2466.01s of remaining time.\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 2465.24s of the 2465.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.976\t = Validation score   (accuracy)\n",
      "\t6.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 2456.91s of the 2456.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t6.63s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 2447.83s of the 2447.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r14_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=23355, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=23355, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 2441.90s of the 2441.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\t0.98\t = Validation score   (accuracy)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 2437.53s of the 2437.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "2024-12-26 08:14:12,690\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:14:12,691\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:14:12,692\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:14:12,694\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:14:12,695\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:14:12,696\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:14:12,697\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t6.81s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 2428.01s of the 2428.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t13.38s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 2411.60s of the 2411.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t6.8s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 2402.46s of the 2402.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.98\t = Validation score   (accuracy)\n",
      "\t1.85s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 2398.14s of the 2398.13s of remaining time.\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t1.45s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 2396.56s of the 2396.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t18.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 2376.21s of the 2376.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t4.83s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 2369.03s of the 2369.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r41_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=26679, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=26679, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 2362.75s of the 2362.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t2.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 2358.09s of the 2358.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "2024-12-26 08:15:31,720\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:31,721\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:31,723\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:31,724\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:31,725\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:31,726\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:31,727\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t2.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 2353.24s of the 2353.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r158_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=27776, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=27776, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r86_BAG_L1 ... Training model for up to 2347.70s of the 2347.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "2024-12-26 08:15:46,726\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:46,728\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:46,731\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:46,733\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:46,735\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:46,736\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:15:47,726\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t27.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 2318.34s of the 2318.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t7.0s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 2309.07s of the 2309.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r197_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=29042, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=29042, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r49_BAG_L1 ... Training model for up to 2303.42s of the 2303.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "2024-12-26 08:16:31,747\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:16:31,751\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:16:31,752\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:16:31,754\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:16:31,755\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:16:31,758\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:16:31,759\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.98\t = Validation score   (accuracy)\n",
      "\t4.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r49_BAG_L1 ... Training model for up to 2296.67s of the 2296.66s of remaining time.\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r143_BAG_L1 ... Training model for up to 2295.36s of the 2295.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t0.976\t = Validation score   (accuracy)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForest_r127_BAG_L1 ... Training model for up to 2291.19s of the 2291.18s of remaining time.\n",
      "\t0.956\t = Validation score   (accuracy)\n",
      "\t1.73s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 2289.35s of the 2289.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t7.56s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForest_r34_BAG_L1 ... Training model for up to 2279.52s of the 2279.50s of remaining time.\n",
      "\t0.868\t = Validation score   (accuracy)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r94_BAG_L1 ... Training model for up to 2278.55s of the 2278.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 2274.66s of the 2274.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r143_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=31078, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=31078, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r128_BAG_L1 ... Training model for up to 2268.77s of the 2268.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
      "2024-12-26 08:17:05,760\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=31075, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2024-12-26 08:17:05,762\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:17:05,763\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:17:05,764\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:17:05,765\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:17:05,766\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:17:05,767\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t26.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 2239.61s of the 2239.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t5.89s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 2231.32s of the 2231.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r31_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=32355, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=32355, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: ExtraTrees_r4_BAG_L1 ... Training model for up to 2225.15s of the 2225.14s of remaining time.\n",
      "\t0.948\t = Validation score   (accuracy)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 2224.38s of the 2224.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "2024-12-26 08:17:49,775\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:17:49,777\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:17:49,778\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:17:49,779\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:17:49,780\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:17:49,781\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:17:49,782\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.968\t = Validation score   (accuracy)\n",
      "\t6.44s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r88_BAG_L1 ... Training model for up to 2215.66s of the 2215.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t6.63s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_r30_BAG_L1 ... Training model for up to 2205.78s of the 2205.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.972\t = Validation score   (accuracy)\n",
      "\t1.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost_r49_BAG_L1 ... Training model for up to 2201.35s of the 2201.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_r5_BAG_L1 ... Training model for up to 2196.96s of the 2196.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t0.98\t = Validation score   (accuracy)\n",
      "\t4.71s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r87_BAG_L1 ... Training model for up to 2189.73s of the 2189.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r87_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=2352, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=2352, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetTorch_r71_BAG_L1 ... Training model for up to 2184.32s of the 2184.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r71_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=2714, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=2714, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2024-12-26 08:18:30,791\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:18:30,792\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:18:30,793\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:18:30,795\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:18:30,797\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:18:30,798\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: CatBoost_r143_BAG_L1 ... Training model for up to 2178.93s of the 2178.92s of remaining time.\n",
      "2024-12-26 08:18:30,799\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "2024-12-26 08:18:35,800\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:18:35,802\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:18:35,803\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:18:35,804\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:18:35,805\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:18:35,806\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:18:35,807\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t18.14s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r178_BAG_L1 ... Training model for up to 2158.43s of the 2158.42s of remaining time.\n",
      "\t0.976\t = Validation score   (accuracy)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForest_r166_BAG_L1 ... Training model for up to 2157.09s of the 2157.08s of remaining time.\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t1.5s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_r31_BAG_L1 ... Training model for up to 2155.48s of the 2155.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t1.82s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r185_BAG_L1 ... Training model for up to 2151.37s of the 2151.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r185_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=4208, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=4208, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r160_BAG_L1 ... Training model for up to 2145.81s of the 2145.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "2024-12-26 08:19:08,813\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:19:08,815\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:19:08,816\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:19:08,817\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:19:08,818\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:19:08,819\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:19:08,820\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.972\t = Validation score   (accuracy)\n",
      "\t4.63s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r60_BAG_L1 ... Training model for up to 2138.82s of the 2138.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.976\t = Validation score   (accuracy)\n",
      "\t6.99s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForest_r15_BAG_L1 ... Training model for up to 2128.59s of the 2128.58s of remaining time.\n",
      "\t0.98\t = Validation score   (accuracy)\n",
      "\t1.36s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r135_BAG_L1 ... Training model for up to 2127.11s of the 2127.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.972\t = Validation score   (accuracy)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost_r22_BAG_L1 ... Training model for up to 2123.01s of the 2123.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r69_BAG_L1 ... Training model for up to 2119.13s of the 2119.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.976\t = Validation score   (accuracy)\n",
      "\t4.88s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r6_BAG_L1 ... Training model for up to 2111.76s of the 2111.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t0.976\t = Validation score   (accuracy)\n",
      "\t5.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r138_BAG_L1 ... Training model for up to 2103.60s of the 2103.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t5.51s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r121_BAG_L1 ... Training model for up to 2095.72s of the 2095.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r172_BAG_L1 ... Training model for up to 2090.68s of the 2090.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t5.96s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_r180_BAG_L1 ... Training model for up to 2081.86s of the 2081.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t22.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r76_BAG_L1 ... Training model for up to 2056.64s of the 2056.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r76_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=8800, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=8800, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: ExtraTrees_r197_BAG_L1 ... Training model for up to 2051.15s of the 2051.14s of remaining time.\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t1.46s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r121_BAG_L1 ... Training model for up to 2049.58s of the 2049.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "2024-12-26 08:20:43,849\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:43,851\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:43,852\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:43,853\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:43,854\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:43,855\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:43,856\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused NeuralNetTorch_r121_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=9195, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=9195, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r127_BAG_L1 ... Training model for up to 2044.15s of the 2044.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "2024-12-26 08:20:50,852\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:50,854\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:50,855\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:50,856\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:50,858\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:50,859\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:20:50,860\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t6.03s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForest_r16_BAG_L1 ... Training model for up to 2035.79s of the 2035.78s of remaining time.\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r194_BAG_L1 ... Training model for up to 2033.56s of the 2033.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t6.21s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_r12_BAG_L1 ... Training model for up to 2025.06s of the 2025.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t22.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r135_BAG_L1 ... Training model for up to 1999.44s of the 1999.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r135_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=10909, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=10909, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r4_BAG_L1 ... Training model for up to 1994.05s of the 1994.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "2024-12-26 08:21:40,872\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:40,876\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:40,877\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:40,879\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:40,880\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:40,884\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:40,885\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t6.2s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r126_BAG_L1 ... Training model for up to 1985.44s of the 1985.43s of remaining time.\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t1.52s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r36_BAG_L1 ... Training model for up to 1983.80s of the 1983.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r36_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=11754, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=11754, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetFastAI_r100_BAG_L1 ... Training model for up to 1978.44s of the 1978.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "2024-12-26 08:21:56,879\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:56,880\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:56,881\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:56,883\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:56,884\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:56,885\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:21:56,886\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t8.05s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r163_BAG_L1 ... Training model for up to 1967.92s of the 1967.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.976\t = Validation score   (accuracy)\n",
      "\t6.31s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_r198_BAG_L1 ... Training model for up to 1958.95s of the 1958.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.976\t = Validation score   (accuracy)\n",
      "\t9.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r187_BAG_L1 ... Training model for up to 1947.03s of the 1947.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t7.44s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r19_BAG_L1 ... Training model for up to 1936.91s of the 1936.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r19_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=13921, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=13921, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r95_BAG_L1 ... Training model for up to 1931.39s of the 1931.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost_r34_BAG_L1 ... Training model for up to 1927.87s of the 1927.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.37%)\n",
      "2024-12-26 08:22:43,902\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:22:43,904\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:22:43,905\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:22:43,906\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:22:43,908\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:22:43,909\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:22:43,910\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_r42_BAG_L1 ... Training model for up to 1923.69s of the 1923.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.984\t = Validation score   (accuracy)\n",
      "\t1.84s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r1_BAG_L1 ... Training model for up to 1919.16s of the 1919.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r1_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=15359, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=15359, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: NeuralNetTorch_r89_BAG_L1 ... Training model for up to 1913.41s of the 1913.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r89_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=15730, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=15730, ip=169.255.255.2)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2024-12-26 08:23:01,726\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:01,728\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:01,729\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:01,730\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:01,731\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:01,732\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:01,734\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1907.98s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestGini_BAG_L1': 1.0}\n",
      "\t0.992\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 788.46s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2715.1 rows/s (250 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/sagemaker-user/AUDIO SENTIMENT ANALYSIS - NUMERIC EMBEDDING/AutogluonModels/ag-20241226_075449\")\n",
      "2024-12-26 08:23:06,910\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:06,911\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:06,912\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:06,912\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:06,913\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:06,913\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-26 08:23:06,914\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=\"Class\",eval_metric = 'accuracy').fit(train_data = data, presets = \"best_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ca2e98-8945-4ec4-ac17-5540309bfb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                          model  score_val eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0          CatBoost_r180_BAG_L1      0.992    accuracy       0.009050  22.084476                0.009050          22.084476            1       True         75\n",
      "1   NeuralNetFastAI_r172_BAG_L1      0.992    accuracy       0.073780   5.961272                0.073780           5.961272            1       True         74\n",
      "2   NeuralNetFastAI_r102_BAG_L1      0.992    accuracy       0.075737   6.076989                0.075737           6.076989            1       True         21\n",
      "3   NeuralNetFastAI_r127_BAG_L1      0.992    accuracy       0.075875   6.033528                0.075875           6.033528            1       True         77\n",
      "4   NeuralNetFastAI_r187_BAG_L1      0.992    accuracy       0.078020   7.443452                0.078020           7.443452            1       True         86\n",
      "5   NeuralNetFastAI_r194_BAG_L1      0.992    accuracy       0.079632   6.205791                0.079632           6.205791            1       True         79\n",
      "6    NeuralNetFastAI_r88_BAG_L1      0.992    accuracy       0.079804   6.632956                0.079804           6.632956            1       True         57\n",
      "7   NeuralNetFastAI_r111_BAG_L1      0.992    accuracy       0.082108   5.886884                0.082108           5.886884            1       True         54\n",
      "8    NeuralNetFastAI_r11_BAG_L1      0.992    accuracy       0.082147   5.062140                0.082147           5.062140            1       True         29\n",
      "9   NeuralNetFastAI_r103_BAG_L1      0.992    accuracy       0.083134   6.626737                0.083134           6.626737            1       True         33\n",
      "10   NeuralNetFastAI_r37_BAG_L1      0.992    accuracy       0.083878   6.996238                0.083878           6.996238            1       True         45\n",
      "11     RandomForest_r166_BAG_L1      0.992    accuracy       0.089427   1.500050                0.089427           1.500050            1       True         63\n",
      "12  NeuralNetFastAI_r134_BAG_L1      0.992    accuracy       0.089678   7.561843                0.089678           7.561843            1       True         50\n",
      "13        ExtraTrees_r49_BAG_L1      0.992    accuracy       0.090673   1.185122                0.090673           1.185122            1       True         47\n",
      "14      RandomForestGini_BAG_L1      0.992    accuracy       0.091267   0.893743                0.091267           0.893743            1       True          6\n",
      "15        ExtraTreesEntr_BAG_L1      0.992    accuracy       0.091828   0.573915                0.091828           0.573915            1       True         10\n",
      "16          WeightedEnsemble_L2      0.992    accuracy       0.092078   0.974993                0.000811           0.081250            2       True         90\n",
      "17  NeuralNetFastAI_r191_BAG_L1      0.992    accuracy       0.092226   7.542321                0.092226           7.542321            1       True         15\n",
      "18        ExtraTreesGini_BAG_L1      0.992    accuracy       0.092590   0.601419                0.092590           0.601419            1       True          9\n",
      "19      RandomForestEntr_BAG_L1      0.992    accuracy       0.092855   0.584353                0.092855           0.584353            1       True          7\n",
      "20         LightGBMLarge_BAG_L1      0.988    accuracy       0.007438   2.872705                0.007438           2.872705            1       True         12\n",
      "21          LightGBM_r15_BAG_L1      0.988    accuracy       0.007571   2.217720                0.007571           2.217720            1       True         43\n",
      "22         CatBoost_r143_BAG_L1      0.988    accuracy       0.010745  18.141982                0.010745          18.141982            1       True         61\n",
      "23           XGBoost_r22_BAG_L1      0.988    accuracy       0.025800   1.187370                0.025800           1.187370            1       True         69\n",
      "24           XGBoost_r49_BAG_L1      0.988    accuracy       0.026742   1.548505                0.026742           1.548505            1       True         59\n",
      "25           XGBoost_r33_BAG_L1      0.988    accuracy       0.026755   1.948763                0.026755           1.948763            1       True         18\n",
      "26  NeuralNetFastAI_r156_BAG_L1      0.988    accuracy       0.074674   6.802362                0.074674           6.802362            1       True         37\n",
      "27    NeuralNetFastAI_r4_BAG_L1      0.988    accuracy       0.078653   6.201619                0.078653           6.201619            1       True         81\n",
      "28       NeuralNetFastAI_BAG_L1      0.988    accuracy       0.081687   6.217460                0.081687           6.217460            1       True          3\n",
      "29  NeuralNetFastAI_r145_BAG_L1      0.988    accuracy       0.084866   4.991792                0.084866           4.991792            1       True         25\n",
      "30      RandomForest_r16_BAG_L1      0.988    accuracy       0.089181   2.113749                0.089181           2.113749            1       True         78\n",
      "31  NeuralNetFastAI_r138_BAG_L1      0.988    accuracy       0.090815   5.508324                0.090815           5.508324            1       True         72\n",
      "32       ExtraTrees_r126_BAG_L1      0.988    accuracy       0.091347   1.524568                0.091347           1.524568            1       True         82\n",
      "33        ExtraTrees_r42_BAG_L1      0.988    accuracy       0.092092   0.778636                0.092092           0.778636            1       True         19\n",
      "34       ExtraTrees_r197_BAG_L1      0.988    accuracy       0.092584   1.458632                0.092584           1.458632            1       True         76\n",
      "35  NeuralNetFastAI_r100_BAG_L1      0.988    accuracy       0.095626   8.054359                0.095626           8.054359            1       True         83\n",
      "36     RandomForest_r195_BAG_L1      0.988    accuracy       0.096428   1.398211                0.096428           1.398211            1       True         23\n",
      "37      RandomForest_r39_BAG_L1      0.988    accuracy       0.102251   1.451874                0.102251           1.451874            1       True         39\n",
      "38         LightGBM_r188_BAG_L1      0.984    accuracy       0.007776   1.812739                0.007776           1.812739            1       True         24\n",
      "39         LightGBM_r121_BAG_L1      0.984    accuracy       0.008541   2.106612                0.008541           2.106612            1       True         73\n",
      "40          LightGBM_r42_BAG_L1      0.984    accuracy       0.009021   1.843222                0.009021           1.843222            1       True         89\n",
      "41          CatBoost_r86_BAG_L1      0.984    accuracy       0.009126  27.021629                0.009126          27.021629            1       True         44\n",
      "42         CatBoost_r128_BAG_L1      0.984    accuracy       0.009864  26.739629                0.009864          26.739629            1       True         53\n",
      "43          LightGBM_r94_BAG_L1      0.984    accuracy       0.010077   1.594535                0.010077           1.594535            1       True         52\n",
      "44         CatBoost_r167_BAG_L1      0.984    accuracy       0.010201  18.102767                0.010201          18.102767            1       True         40\n",
      "45          CatBoost_r13_BAG_L1      0.984    accuracy       0.010374  33.162158                0.010374          33.162158            1       True         22\n",
      "46           CatBoost_r9_BAG_L1      0.984    accuracy       0.010506  26.189136                0.010506          26.189136            1       True         16\n",
      "47          CatBoost_r12_BAG_L1      0.984    accuracy       0.012874  22.413590                0.012874          22.413590            1       True         80\n",
      "48          CatBoost_r70_BAG_L1      0.984    accuracy       0.015367  13.375646                0.015367          13.375646            1       True         36\n",
      "49           XGBoost_r31_BAG_L1      0.984    accuracy       0.023945   1.823665                0.023945           1.823665            1       True         64\n",
      "50           XGBoost_r89_BAG_L1      0.984    accuracy       0.024362   1.140186                0.024362           1.140186            1       True         26\n",
      "51           XGBoost_r95_BAG_L1      0.984    accuracy       0.025054   1.057495                0.025054           1.057495            1       True         87\n",
      "52           XGBoost_r34_BAG_L1      0.984    accuracy       0.026122   1.399521                0.026122           1.399521            1       True         88\n",
      "53           XGBoost_r98_BAG_L1      0.984    accuracy       0.029989   2.341177                0.029989           2.341177            1       True         42\n",
      "54          XGBoost_r194_BAG_L1      0.984    accuracy       0.037880   1.737881                0.037880           1.737881            1       True         30\n",
      "55  NeuralNetFastAI_r143_BAG_L1      0.984    accuracy       0.079818   6.812265                0.079818           6.812265            1       True         35\n",
      "56   NeuralNetFastAI_r95_BAG_L1      0.984    accuracy       0.081148   4.829204                0.081148           4.829204            1       True         41\n",
      "57       ExtraTrees_r172_BAG_L1      0.984    accuracy       0.091889   0.669273                0.091889           0.669273            1       True         31\n",
      "58            LightGBMXT_BAG_L1      0.980    accuracy       0.007545   1.818145                0.007545           1.818145            1       True          4\n",
      "59         LightGBM_r161_BAG_L1      0.980    accuracy       0.008286   2.051080                0.008286           2.051080            1       True         34\n",
      "60         LightGBM_r131_BAG_L1      0.980    accuracy       0.008601   1.901187                0.008601           1.901187            1       True         14\n",
      "61         LightGBM_r196_BAG_L1      0.980    accuracy       0.008966   1.850573                0.008966           1.850573            1       True         38\n",
      "62           CatBoost_r5_BAG_L1      0.980    accuracy       0.009975   4.712171                0.009975           4.712171            1       True         60\n",
      "63         CatBoost_r137_BAG_L1      0.980    accuracy       0.010188   4.423008                0.010188           4.423008            1       True         20\n",
      "64              CatBoost_BAG_L1      0.980    accuracy       0.010486   9.548300                0.010486           9.548300            1       True          8\n",
      "65          CatBoost_r49_BAG_L1      0.980    accuracy       0.010651   4.479272                0.010651           4.479272            1       True         46\n",
      "66         CatBoost_r177_BAG_L1      0.980    accuracy       0.010874  10.281142                0.010874          10.281142            1       True         13\n",
      "67               XGBoost_BAG_L1      0.980    accuracy       0.025923   1.076125                0.025923           1.076125            1       True         11\n",
      "68      RandomForest_r15_BAG_L1      0.980    accuracy       0.089868   1.362282                0.089868           1.362282            1       True         67\n",
      "69           CatBoost_r6_BAG_L1      0.976    accuracy       0.009348   5.001390                0.009348           5.001390            1       True         71\n",
      "70         LightGBM_r143_BAG_L1      0.976    accuracy       0.009570   1.812913                0.009570           1.812913            1       True         48\n",
      "71          CatBoost_r60_BAG_L1      0.976    accuracy       0.010287   6.989346                0.010287           6.989346            1       True         66\n",
      "72         CatBoost_r163_BAG_L1      0.976    accuracy       0.010351   6.307940                0.010351           6.307940            1       True         84\n",
      "73          CatBoost_r69_BAG_L1      0.976    accuracy       0.010669   6.046449                0.010669           6.046449            1       True         32\n",
      "74         CatBoost_r198_BAG_L1      0.976    accuracy       0.011591   9.516669                0.011591           9.516669            1       True         85\n",
      "75              LightGBM_BAG_L1      0.976    accuracy       0.015471   1.732314                0.015471           1.732314            1       True          5\n",
      "76   NeuralNetFastAI_r69_BAG_L1      0.976    accuracy       0.076747   4.880297                0.076747           4.880297            1       True         70\n",
      "77       ExtraTrees_r178_BAG_L1      0.976    accuracy       0.091029   1.223406                0.091029           1.223406            1       True         62\n",
      "78         LightGBM_r130_BAG_L1      0.972    accuracy       0.007731   1.591697                0.007731           1.591697            1       True         27\n",
      "79         LightGBM_r135_BAG_L1      0.972    accuracy       0.008905   1.805623                0.008905           1.805623            1       True         68\n",
      "80          CatBoost_r50_BAG_L1      0.972    accuracy       0.009244   5.033226                0.009244           5.033226            1       True         28\n",
      "81          LightGBM_r30_BAG_L1      0.972    accuracy       0.010307   1.744076                0.010307           1.744076            1       True         58\n",
      "82  NeuralNetFastAI_r160_BAG_L1      0.972    accuracy       0.093613   4.630310                0.093613           4.630310            1       True         65\n",
      "83          LightGBM_r96_BAG_L1      0.968    accuracy       0.009189   1.655733                0.009189           1.655733            1       True         17\n",
      "84   NeuralNetFastAI_r65_BAG_L1      0.968    accuracy       0.066791   6.443866                0.066791           6.443866            1       True         56\n",
      "85     RandomForest_r127_BAG_L1      0.956    accuracy       0.089840   1.728445                0.089840           1.728445            1       True         49\n",
      "86         ExtraTrees_r4_BAG_L1      0.948    accuracy       0.089224   0.660131                0.089224           0.660131            1       True         55\n",
      "87        KNeighborsDist_BAG_L1      0.908    accuracy       0.002100   0.006468                0.002100           0.006468            1       True          2\n",
      "88      RandomForest_r34_BAG_L1      0.868    accuracy       0.103782   0.842023                0.103782           0.842023            1       True         51\n",
      "89        KNeighborsUnif_BAG_L1      0.856    accuracy       0.047665   0.004746                0.047665           0.004746            1       True          1\n",
      "Number of models trained: 90\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_XT'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 26 | ['0', '1', '2', '3', '4', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/autogluon/core/utils/plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForestGini_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'RandomForestEntr_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTreesGini_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'ExtraTreesEntr_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r177_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r131_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r9_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'LightGBM_r96_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r33_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'ExtraTrees_r42_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'CatBoost_r137_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r13_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'RandomForest_r195_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'LightGBM_r188_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r89_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r130_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r50_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r194_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'ExtraTrees_r172_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'CatBoost_r69_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r161_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r70_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r196_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForest_r39_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_r167_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r98_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r15_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r86_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r49_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTrees_r49_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'LightGBM_r143_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForest_r127_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'RandomForest_r34_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'LightGBM_r94_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_r128_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'ExtraTrees_r4_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r30_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r49_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'CatBoost_r5_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_r143_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTrees_r178_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'RandomForest_r166_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'XGBoost_r31_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r60_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'RandomForest_r15_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'LightGBM_r135_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'XGBoost_r22_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r6_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBM_r121_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r180_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTrees_r197_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'RandomForest_r16_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r12_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'ExtraTrees_r126_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'CatBoost_r163_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'CatBoost_r198_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_r95_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'XGBoost_r34_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'LightGBM_r42_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': 0.856,\n",
       "  'KNeighborsDist_BAG_L1': 0.908,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.988,\n",
       "  'LightGBMXT_BAG_L1': 0.98,\n",
       "  'LightGBM_BAG_L1': 0.976,\n",
       "  'RandomForestGini_BAG_L1': 0.992,\n",
       "  'RandomForestEntr_BAG_L1': 0.992,\n",
       "  'CatBoost_BAG_L1': 0.98,\n",
       "  'ExtraTreesGini_BAG_L1': 0.992,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.992,\n",
       "  'XGBoost_BAG_L1': 0.98,\n",
       "  'LightGBMLarge_BAG_L1': 0.988,\n",
       "  'CatBoost_r177_BAG_L1': 0.98,\n",
       "  'LightGBM_r131_BAG_L1': 0.98,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.992,\n",
       "  'CatBoost_r9_BAG_L1': 0.984,\n",
       "  'LightGBM_r96_BAG_L1': 0.968,\n",
       "  'XGBoost_r33_BAG_L1': 0.988,\n",
       "  'ExtraTrees_r42_BAG_L1': 0.988,\n",
       "  'CatBoost_r137_BAG_L1': 0.98,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.992,\n",
       "  'CatBoost_r13_BAG_L1': 0.984,\n",
       "  'RandomForest_r195_BAG_L1': 0.988,\n",
       "  'LightGBM_r188_BAG_L1': 0.984,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 0.988,\n",
       "  'XGBoost_r89_BAG_L1': 0.984,\n",
       "  'LightGBM_r130_BAG_L1': 0.972,\n",
       "  'CatBoost_r50_BAG_L1': 0.972,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 0.992,\n",
       "  'XGBoost_r194_BAG_L1': 0.984,\n",
       "  'ExtraTrees_r172_BAG_L1': 0.984,\n",
       "  'CatBoost_r69_BAG_L1': 0.976,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 0.992,\n",
       "  'LightGBM_r161_BAG_L1': 0.98,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 0.984,\n",
       "  'CatBoost_r70_BAG_L1': 0.984,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 0.988,\n",
       "  'LightGBM_r196_BAG_L1': 0.98,\n",
       "  'RandomForest_r39_BAG_L1': 0.988,\n",
       "  'CatBoost_r167_BAG_L1': 0.984,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 0.984,\n",
       "  'XGBoost_r98_BAG_L1': 0.984,\n",
       "  'LightGBM_r15_BAG_L1': 0.988,\n",
       "  'CatBoost_r86_BAG_L1': 0.984,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 0.992,\n",
       "  'CatBoost_r49_BAG_L1': 0.98,\n",
       "  'ExtraTrees_r49_BAG_L1': 0.992,\n",
       "  'LightGBM_r143_BAG_L1': 0.976,\n",
       "  'RandomForest_r127_BAG_L1': 0.956,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 0.992,\n",
       "  'RandomForest_r34_BAG_L1': 0.868,\n",
       "  'LightGBM_r94_BAG_L1': 0.984,\n",
       "  'CatBoost_r128_BAG_L1': 0.984,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 0.992,\n",
       "  'ExtraTrees_r4_BAG_L1': 0.948,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 0.968,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 0.992,\n",
       "  'LightGBM_r30_BAG_L1': 0.972,\n",
       "  'XGBoost_r49_BAG_L1': 0.988,\n",
       "  'CatBoost_r5_BAG_L1': 0.98,\n",
       "  'CatBoost_r143_BAG_L1': 0.988,\n",
       "  'ExtraTrees_r178_BAG_L1': 0.976,\n",
       "  'RandomForest_r166_BAG_L1': 0.992,\n",
       "  'XGBoost_r31_BAG_L1': 0.984,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 0.972,\n",
       "  'CatBoost_r60_BAG_L1': 0.976,\n",
       "  'RandomForest_r15_BAG_L1': 0.98,\n",
       "  'LightGBM_r135_BAG_L1': 0.972,\n",
       "  'XGBoost_r22_BAG_L1': 0.988,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 0.976,\n",
       "  'CatBoost_r6_BAG_L1': 0.976,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 0.988,\n",
       "  'LightGBM_r121_BAG_L1': 0.984,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 0.992,\n",
       "  'CatBoost_r180_BAG_L1': 0.992,\n",
       "  'ExtraTrees_r197_BAG_L1': 0.988,\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 0.992,\n",
       "  'RandomForest_r16_BAG_L1': 0.988,\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 0.992,\n",
       "  'CatBoost_r12_BAG_L1': 0.984,\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 0.988,\n",
       "  'ExtraTrees_r126_BAG_L1': 0.988,\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 0.988,\n",
       "  'CatBoost_r163_BAG_L1': 0.976,\n",
       "  'CatBoost_r198_BAG_L1': 0.976,\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 0.992,\n",
       "  'XGBoost_r95_BAG_L1': 0.984,\n",
       "  'XGBoost_r34_BAG_L1': 0.984,\n",
       "  'LightGBM_r42_BAG_L1': 0.984,\n",
       "  'WeightedEnsemble_L2': 0.992},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': ['KNeighborsUnif_BAG_L1'],\n",
       "  'KNeighborsDist_BAG_L1': ['KNeighborsDist_BAG_L1'],\n",
       "  'NeuralNetFastAI_BAG_L1': ['NeuralNetFastAI_BAG_L1'],\n",
       "  'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
       "  'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'RandomForestGini_BAG_L1': ['RandomForestGini_BAG_L1'],\n",
       "  'RandomForestEntr_BAG_L1': ['RandomForestEntr_BAG_L1'],\n",
       "  'CatBoost_BAG_L1': ['CatBoost_BAG_L1'],\n",
       "  'ExtraTreesGini_BAG_L1': ['ExtraTreesGini_BAG_L1'],\n",
       "  'ExtraTreesEntr_BAG_L1': ['ExtraTreesEntr_BAG_L1'],\n",
       "  'XGBoost_BAG_L1': ['XGBoost_BAG_L1'],\n",
       "  'LightGBMLarge_BAG_L1': ['LightGBMLarge_BAG_L1'],\n",
       "  'CatBoost_r177_BAG_L1': ['CatBoost_r177_BAG_L1'],\n",
       "  'LightGBM_r131_BAG_L1': ['LightGBM_r131_BAG_L1'],\n",
       "  'NeuralNetFastAI_r191_BAG_L1': ['NeuralNetFastAI_r191_BAG_L1'],\n",
       "  'CatBoost_r9_BAG_L1': ['CatBoost_r9_BAG_L1'],\n",
       "  'LightGBM_r96_BAG_L1': ['LightGBM_r96_BAG_L1'],\n",
       "  'XGBoost_r33_BAG_L1': ['XGBoost_r33_BAG_L1'],\n",
       "  'ExtraTrees_r42_BAG_L1': ['ExtraTrees_r42_BAG_L1'],\n",
       "  'CatBoost_r137_BAG_L1': ['CatBoost_r137_BAG_L1'],\n",
       "  'NeuralNetFastAI_r102_BAG_L1': ['NeuralNetFastAI_r102_BAG_L1'],\n",
       "  'CatBoost_r13_BAG_L1': ['CatBoost_r13_BAG_L1'],\n",
       "  'RandomForest_r195_BAG_L1': ['RandomForest_r195_BAG_L1'],\n",
       "  'LightGBM_r188_BAG_L1': ['LightGBM_r188_BAG_L1'],\n",
       "  'NeuralNetFastAI_r145_BAG_L1': ['NeuralNetFastAI_r145_BAG_L1'],\n",
       "  'XGBoost_r89_BAG_L1': ['XGBoost_r89_BAG_L1'],\n",
       "  'LightGBM_r130_BAG_L1': ['LightGBM_r130_BAG_L1'],\n",
       "  'CatBoost_r50_BAG_L1': ['CatBoost_r50_BAG_L1'],\n",
       "  'NeuralNetFastAI_r11_BAG_L1': ['NeuralNetFastAI_r11_BAG_L1'],\n",
       "  'XGBoost_r194_BAG_L1': ['XGBoost_r194_BAG_L1'],\n",
       "  'ExtraTrees_r172_BAG_L1': ['ExtraTrees_r172_BAG_L1'],\n",
       "  'CatBoost_r69_BAG_L1': ['CatBoost_r69_BAG_L1'],\n",
       "  'NeuralNetFastAI_r103_BAG_L1': ['NeuralNetFastAI_r103_BAG_L1'],\n",
       "  'LightGBM_r161_BAG_L1': ['LightGBM_r161_BAG_L1'],\n",
       "  'NeuralNetFastAI_r143_BAG_L1': ['NeuralNetFastAI_r143_BAG_L1'],\n",
       "  'CatBoost_r70_BAG_L1': ['CatBoost_r70_BAG_L1'],\n",
       "  'NeuralNetFastAI_r156_BAG_L1': ['NeuralNetFastAI_r156_BAG_L1'],\n",
       "  'LightGBM_r196_BAG_L1': ['LightGBM_r196_BAG_L1'],\n",
       "  'RandomForest_r39_BAG_L1': ['RandomForest_r39_BAG_L1'],\n",
       "  'CatBoost_r167_BAG_L1': ['CatBoost_r167_BAG_L1'],\n",
       "  'NeuralNetFastAI_r95_BAG_L1': ['NeuralNetFastAI_r95_BAG_L1'],\n",
       "  'XGBoost_r98_BAG_L1': ['XGBoost_r98_BAG_L1'],\n",
       "  'LightGBM_r15_BAG_L1': ['LightGBM_r15_BAG_L1'],\n",
       "  'CatBoost_r86_BAG_L1': ['CatBoost_r86_BAG_L1'],\n",
       "  'NeuralNetFastAI_r37_BAG_L1': ['NeuralNetFastAI_r37_BAG_L1'],\n",
       "  'CatBoost_r49_BAG_L1': ['CatBoost_r49_BAG_L1'],\n",
       "  'ExtraTrees_r49_BAG_L1': ['ExtraTrees_r49_BAG_L1'],\n",
       "  'LightGBM_r143_BAG_L1': ['LightGBM_r143_BAG_L1'],\n",
       "  'RandomForest_r127_BAG_L1': ['RandomForest_r127_BAG_L1'],\n",
       "  'NeuralNetFastAI_r134_BAG_L1': ['NeuralNetFastAI_r134_BAG_L1'],\n",
       "  'RandomForest_r34_BAG_L1': ['RandomForest_r34_BAG_L1'],\n",
       "  'LightGBM_r94_BAG_L1': ['LightGBM_r94_BAG_L1'],\n",
       "  'CatBoost_r128_BAG_L1': ['CatBoost_r128_BAG_L1'],\n",
       "  'NeuralNetFastAI_r111_BAG_L1': ['NeuralNetFastAI_r111_BAG_L1'],\n",
       "  'ExtraTrees_r4_BAG_L1': ['ExtraTrees_r4_BAG_L1'],\n",
       "  'NeuralNetFastAI_r65_BAG_L1': ['NeuralNetFastAI_r65_BAG_L1'],\n",
       "  'NeuralNetFastAI_r88_BAG_L1': ['NeuralNetFastAI_r88_BAG_L1'],\n",
       "  'LightGBM_r30_BAG_L1': ['LightGBM_r30_BAG_L1'],\n",
       "  'XGBoost_r49_BAG_L1': ['XGBoost_r49_BAG_L1'],\n",
       "  'CatBoost_r5_BAG_L1': ['CatBoost_r5_BAG_L1'],\n",
       "  'CatBoost_r143_BAG_L1': ['CatBoost_r143_BAG_L1'],\n",
       "  'ExtraTrees_r178_BAG_L1': ['ExtraTrees_r178_BAG_L1'],\n",
       "  'RandomForest_r166_BAG_L1': ['RandomForest_r166_BAG_L1'],\n",
       "  'XGBoost_r31_BAG_L1': ['XGBoost_r31_BAG_L1'],\n",
       "  'NeuralNetFastAI_r160_BAG_L1': ['NeuralNetFastAI_r160_BAG_L1'],\n",
       "  'CatBoost_r60_BAG_L1': ['CatBoost_r60_BAG_L1'],\n",
       "  'RandomForest_r15_BAG_L1': ['RandomForest_r15_BAG_L1'],\n",
       "  'LightGBM_r135_BAG_L1': ['LightGBM_r135_BAG_L1'],\n",
       "  'XGBoost_r22_BAG_L1': ['XGBoost_r22_BAG_L1'],\n",
       "  'NeuralNetFastAI_r69_BAG_L1': ['NeuralNetFastAI_r69_BAG_L1'],\n",
       "  'CatBoost_r6_BAG_L1': ['CatBoost_r6_BAG_L1'],\n",
       "  'NeuralNetFastAI_r138_BAG_L1': ['NeuralNetFastAI_r138_BAG_L1'],\n",
       "  'LightGBM_r121_BAG_L1': ['LightGBM_r121_BAG_L1'],\n",
       "  'NeuralNetFastAI_r172_BAG_L1': ['NeuralNetFastAI_r172_BAG_L1'],\n",
       "  'CatBoost_r180_BAG_L1': ['CatBoost_r180_BAG_L1'],\n",
       "  'ExtraTrees_r197_BAG_L1': ['ExtraTrees_r197_BAG_L1'],\n",
       "  'NeuralNetFastAI_r127_BAG_L1': ['NeuralNetFastAI_r127_BAG_L1'],\n",
       "  'RandomForest_r16_BAG_L1': ['RandomForest_r16_BAG_L1'],\n",
       "  'NeuralNetFastAI_r194_BAG_L1': ['NeuralNetFastAI_r194_BAG_L1'],\n",
       "  'CatBoost_r12_BAG_L1': ['CatBoost_r12_BAG_L1'],\n",
       "  'NeuralNetFastAI_r4_BAG_L1': ['NeuralNetFastAI_r4_BAG_L1'],\n",
       "  'ExtraTrees_r126_BAG_L1': ['ExtraTrees_r126_BAG_L1'],\n",
       "  'NeuralNetFastAI_r100_BAG_L1': ['NeuralNetFastAI_r100_BAG_L1'],\n",
       "  'CatBoost_r163_BAG_L1': ['CatBoost_r163_BAG_L1'],\n",
       "  'CatBoost_r198_BAG_L1': ['CatBoost_r198_BAG_L1'],\n",
       "  'NeuralNetFastAI_r187_BAG_L1': ['NeuralNetFastAI_r187_BAG_L1'],\n",
       "  'XGBoost_r95_BAG_L1': ['XGBoost_r95_BAG_L1'],\n",
       "  'XGBoost_r34_BAG_L1': ['XGBoost_r34_BAG_L1'],\n",
       "  'LightGBM_r42_BAG_L1': ['LightGBM_r42_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2']},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.004746437072753906,\n",
       "  'KNeighborsDist_BAG_L1': 0.0064678192138671875,\n",
       "  'NeuralNetFastAI_BAG_L1': 6.217459678649902,\n",
       "  'LightGBMXT_BAG_L1': 1.8181445598602295,\n",
       "  'LightGBM_BAG_L1': 1.732313632965088,\n",
       "  'RandomForestGini_BAG_L1': 0.8937427997589111,\n",
       "  'RandomForestEntr_BAG_L1': 0.5843534469604492,\n",
       "  'CatBoost_BAG_L1': 9.548299789428711,\n",
       "  'ExtraTreesGini_BAG_L1': 0.60141921043396,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.5739152431488037,\n",
       "  'XGBoost_BAG_L1': 1.076124668121338,\n",
       "  'LightGBMLarge_BAG_L1': 2.87270450592041,\n",
       "  'CatBoost_r177_BAG_L1': 10.281142234802246,\n",
       "  'LightGBM_r131_BAG_L1': 1.9011874198913574,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 7.542321443557739,\n",
       "  'CatBoost_r9_BAG_L1': 26.189135551452637,\n",
       "  'LightGBM_r96_BAG_L1': 1.6557326316833496,\n",
       "  'XGBoost_r33_BAG_L1': 1.948763132095337,\n",
       "  'ExtraTrees_r42_BAG_L1': 0.7786355018615723,\n",
       "  'CatBoost_r137_BAG_L1': 4.4230077266693115,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 6.076988697052002,\n",
       "  'CatBoost_r13_BAG_L1': 33.162158489227295,\n",
       "  'RandomForest_r195_BAG_L1': 1.3982114791870117,\n",
       "  'LightGBM_r188_BAG_L1': 1.8127391338348389,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 4.991792440414429,\n",
       "  'XGBoost_r89_BAG_L1': 1.1401863098144531,\n",
       "  'LightGBM_r130_BAG_L1': 1.5916967391967773,\n",
       "  'CatBoost_r50_BAG_L1': 5.033226251602173,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 5.062139511108398,\n",
       "  'XGBoost_r194_BAG_L1': 1.7378811836242676,\n",
       "  'ExtraTrees_r172_BAG_L1': 0.6692733764648438,\n",
       "  'CatBoost_r69_BAG_L1': 6.046449422836304,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 6.626736640930176,\n",
       "  'LightGBM_r161_BAG_L1': 2.0510799884796143,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 6.812265396118164,\n",
       "  'CatBoost_r70_BAG_L1': 13.375645875930786,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 6.802362442016602,\n",
       "  'LightGBM_r196_BAG_L1': 1.8505728244781494,\n",
       "  'RandomForest_r39_BAG_L1': 1.451874017715454,\n",
       "  'CatBoost_r167_BAG_L1': 18.1027672290802,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 4.829204082489014,\n",
       "  'XGBoost_r98_BAG_L1': 2.3411765098571777,\n",
       "  'LightGBM_r15_BAG_L1': 2.217719793319702,\n",
       "  'CatBoost_r86_BAG_L1': 27.021628618240356,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 6.9962379932403564,\n",
       "  'CatBoost_r49_BAG_L1': 4.47927188873291,\n",
       "  'ExtraTrees_r49_BAG_L1': 1.1851224899291992,\n",
       "  'LightGBM_r143_BAG_L1': 1.812913179397583,\n",
       "  'RandomForest_r127_BAG_L1': 1.7284448146820068,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 7.561842918395996,\n",
       "  'RandomForest_r34_BAG_L1': 0.8420226573944092,\n",
       "  'LightGBM_r94_BAG_L1': 1.5945346355438232,\n",
       "  'CatBoost_r128_BAG_L1': 26.73962903022766,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 5.886883974075317,\n",
       "  'ExtraTrees_r4_BAG_L1': 0.6601309776306152,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 6.443866491317749,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 6.63295578956604,\n",
       "  'LightGBM_r30_BAG_L1': 1.7440757751464844,\n",
       "  'XGBoost_r49_BAG_L1': 1.5485053062438965,\n",
       "  'CatBoost_r5_BAG_L1': 4.712170839309692,\n",
       "  'CatBoost_r143_BAG_L1': 18.141982078552246,\n",
       "  'ExtraTrees_r178_BAG_L1': 1.2234055995941162,\n",
       "  'RandomForest_r166_BAG_L1': 1.5000495910644531,\n",
       "  'XGBoost_r31_BAG_L1': 1.823664665222168,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 4.630310297012329,\n",
       "  'CatBoost_r60_BAG_L1': 6.9893457889556885,\n",
       "  'RandomForest_r15_BAG_L1': 1.3622815608978271,\n",
       "  'LightGBM_r135_BAG_L1': 1.8056225776672363,\n",
       "  'XGBoost_r22_BAG_L1': 1.1873695850372314,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 4.88029670715332,\n",
       "  'CatBoost_r6_BAG_L1': 5.001390218734741,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 5.508324384689331,\n",
       "  'LightGBM_r121_BAG_L1': 2.106611967086792,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 5.961271524429321,\n",
       "  'CatBoost_r180_BAG_L1': 22.084476470947266,\n",
       "  'ExtraTrees_r197_BAG_L1': 1.4586317539215088,\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 6.033527612686157,\n",
       "  'RandomForest_r16_BAG_L1': 2.113748788833618,\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 6.205791234970093,\n",
       "  'CatBoost_r12_BAG_L1': 22.41358971595764,\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 6.201618909835815,\n",
       "  'ExtraTrees_r126_BAG_L1': 1.5245680809020996,\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 8.054359197616577,\n",
       "  'CatBoost_r163_BAG_L1': 6.3079400062561035,\n",
       "  'CatBoost_r198_BAG_L1': 9.516669034957886,\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 7.44345235824585,\n",
       "  'XGBoost_r95_BAG_L1': 1.057494878768921,\n",
       "  'XGBoost_r34_BAG_L1': 1.3995206356048584,\n",
       "  'LightGBM_r42_BAG_L1': 1.84322190284729,\n",
       "  'WeightedEnsemble_L2': 0.08124971389770508},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.04766511917114258,\n",
       "  'KNeighborsDist_BAG_L1': 0.002099752426147461,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.08168673515319824,\n",
       "  'LightGBMXT_BAG_L1': 0.007544994354248047,\n",
       "  'LightGBM_BAG_L1': 0.015471220016479492,\n",
       "  'RandomForestGini_BAG_L1': 0.09126687049865723,\n",
       "  'RandomForestEntr_BAG_L1': 0.09285473823547363,\n",
       "  'CatBoost_BAG_L1': 0.01048588752746582,\n",
       "  'ExtraTreesGini_BAG_L1': 0.0925896167755127,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.0918276309967041,\n",
       "  'XGBoost_BAG_L1': 0.025922775268554688,\n",
       "  'LightGBMLarge_BAG_L1': 0.0074384212493896484,\n",
       "  'CatBoost_r177_BAG_L1': 0.010873556137084961,\n",
       "  'LightGBM_r131_BAG_L1': 0.008601188659667969,\n",
       "  'NeuralNetFastAI_r191_BAG_L1': 0.09222626686096191,\n",
       "  'CatBoost_r9_BAG_L1': 0.01050567626953125,\n",
       "  'LightGBM_r96_BAG_L1': 0.009188652038574219,\n",
       "  'XGBoost_r33_BAG_L1': 0.02675461769104004,\n",
       "  'ExtraTrees_r42_BAG_L1': 0.09209203720092773,\n",
       "  'CatBoost_r137_BAG_L1': 0.010187864303588867,\n",
       "  'NeuralNetFastAI_r102_BAG_L1': 0.07573723793029785,\n",
       "  'CatBoost_r13_BAG_L1': 0.010373830795288086,\n",
       "  'RandomForest_r195_BAG_L1': 0.09642791748046875,\n",
       "  'LightGBM_r188_BAG_L1': 0.0077762603759765625,\n",
       "  'NeuralNetFastAI_r145_BAG_L1': 0.08486604690551758,\n",
       "  'XGBoost_r89_BAG_L1': 0.024361848831176758,\n",
       "  'LightGBM_r130_BAG_L1': 0.007730722427368164,\n",
       "  'CatBoost_r50_BAG_L1': 0.00924372673034668,\n",
       "  'NeuralNetFastAI_r11_BAG_L1': 0.08214712142944336,\n",
       "  'XGBoost_r194_BAG_L1': 0.03787994384765625,\n",
       "  'ExtraTrees_r172_BAG_L1': 0.0918891429901123,\n",
       "  'CatBoost_r69_BAG_L1': 0.01066899299621582,\n",
       "  'NeuralNetFastAI_r103_BAG_L1': 0.08313417434692383,\n",
       "  'LightGBM_r161_BAG_L1': 0.008285999298095703,\n",
       "  'NeuralNetFastAI_r143_BAG_L1': 0.0798184871673584,\n",
       "  'CatBoost_r70_BAG_L1': 0.015366554260253906,\n",
       "  'NeuralNetFastAI_r156_BAG_L1': 0.07467389106750488,\n",
       "  'LightGBM_r196_BAG_L1': 0.008966445922851562,\n",
       "  'RandomForest_r39_BAG_L1': 0.10225081443786621,\n",
       "  'CatBoost_r167_BAG_L1': 0.010201215744018555,\n",
       "  'NeuralNetFastAI_r95_BAG_L1': 0.08114814758300781,\n",
       "  'XGBoost_r98_BAG_L1': 0.029988765716552734,\n",
       "  'LightGBM_r15_BAG_L1': 0.00757145881652832,\n",
       "  'CatBoost_r86_BAG_L1': 0.009126424789428711,\n",
       "  'NeuralNetFastAI_r37_BAG_L1': 0.0838780403137207,\n",
       "  'CatBoost_r49_BAG_L1': 0.010651350021362305,\n",
       "  'ExtraTrees_r49_BAG_L1': 0.09067296981811523,\n",
       "  'LightGBM_r143_BAG_L1': 0.009570121765136719,\n",
       "  'RandomForest_r127_BAG_L1': 0.08984041213989258,\n",
       "  'NeuralNetFastAI_r134_BAG_L1': 0.08967757225036621,\n",
       "  'RandomForest_r34_BAG_L1': 0.10378193855285645,\n",
       "  'LightGBM_r94_BAG_L1': 0.01007699966430664,\n",
       "  'CatBoost_r128_BAG_L1': 0.009864330291748047,\n",
       "  'NeuralNetFastAI_r111_BAG_L1': 0.0821084976196289,\n",
       "  'ExtraTrees_r4_BAG_L1': 0.08922433853149414,\n",
       "  'NeuralNetFastAI_r65_BAG_L1': 0.06679105758666992,\n",
       "  'NeuralNetFastAI_r88_BAG_L1': 0.0798044204711914,\n",
       "  'LightGBM_r30_BAG_L1': 0.010306596755981445,\n",
       "  'XGBoost_r49_BAG_L1': 0.026741981506347656,\n",
       "  'CatBoost_r5_BAG_L1': 0.009975194931030273,\n",
       "  'CatBoost_r143_BAG_L1': 0.01074528694152832,\n",
       "  'ExtraTrees_r178_BAG_L1': 0.09102892875671387,\n",
       "  'RandomForest_r166_BAG_L1': 0.08942699432373047,\n",
       "  'XGBoost_r31_BAG_L1': 0.023945331573486328,\n",
       "  'NeuralNetFastAI_r160_BAG_L1': 0.0936129093170166,\n",
       "  'CatBoost_r60_BAG_L1': 0.010286808013916016,\n",
       "  'RandomForest_r15_BAG_L1': 0.08986830711364746,\n",
       "  'LightGBM_r135_BAG_L1': 0.008905172348022461,\n",
       "  'XGBoost_r22_BAG_L1': 0.02579951286315918,\n",
       "  'NeuralNetFastAI_r69_BAG_L1': 0.07674741744995117,\n",
       "  'CatBoost_r6_BAG_L1': 0.009348392486572266,\n",
       "  'NeuralNetFastAI_r138_BAG_L1': 0.09081459045410156,\n",
       "  'LightGBM_r121_BAG_L1': 0.008541345596313477,\n",
       "  'NeuralNetFastAI_r172_BAG_L1': 0.07378005981445312,\n",
       "  'CatBoost_r180_BAG_L1': 0.009050130844116211,\n",
       "  'ExtraTrees_r197_BAG_L1': 0.09258413314819336,\n",
       "  'NeuralNetFastAI_r127_BAG_L1': 0.07587480545043945,\n",
       "  'RandomForest_r16_BAG_L1': 0.08918070793151855,\n",
       "  'NeuralNetFastAI_r194_BAG_L1': 0.07963204383850098,\n",
       "  'CatBoost_r12_BAG_L1': 0.012874126434326172,\n",
       "  'NeuralNetFastAI_r4_BAG_L1': 0.07865309715270996,\n",
       "  'ExtraTrees_r126_BAG_L1': 0.09134745597839355,\n",
       "  'NeuralNetFastAI_r100_BAG_L1': 0.0956263542175293,\n",
       "  'CatBoost_r163_BAG_L1': 0.010350942611694336,\n",
       "  'CatBoost_r198_BAG_L1': 0.011591434478759766,\n",
       "  'NeuralNetFastAI_r187_BAG_L1': 0.07802009582519531,\n",
       "  'XGBoost_r95_BAG_L1': 0.025053739547729492,\n",
       "  'XGBoost_r34_BAG_L1': 0.026122331619262695,\n",
       "  'LightGBM_r42_BAG_L1': 0.009020805358886719,\n",
       "  'WeightedEnsemble_L2': 0.0008111000061035156},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 2,\n",
       " 'num_classes': 3,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForestGini_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'RandomForestEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTreesGini_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'ExtraTreesEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r177_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r131_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r191_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r9_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r96_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r33_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r42_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_r137_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r102_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r13_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r195_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBM_r188_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r145_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r89_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r130_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r50_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r11_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r194_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r172_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_r69_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r103_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r161_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r70_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r156_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r196_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r39_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_r167_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r95_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r98_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r15_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r86_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r37_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBM_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r127_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_r134_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r34_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBM_r94_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r128_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r111_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r4_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_r65_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r88_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r30_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r49_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r5_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r143_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r178_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'RandomForest_r166_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'XGBoost_r31_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r160_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r60_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r15_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBM_r135_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r22_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r69_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r6_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r138_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r121_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r172_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r180_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r197_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_r127_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForest_r16_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_r194_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r12_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r4_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTrees_r126_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_r100_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r163_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_r198_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetFastAI_r187_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r95_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_r34_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_r42_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                           model  score_val  ... can_infer  fit_order\n",
       " 0          CatBoost_r180_BAG_L1      0.992  ...      True         75\n",
       " 1   NeuralNetFastAI_r172_BAG_L1      0.992  ...      True         74\n",
       " 2   NeuralNetFastAI_r102_BAG_L1      0.992  ...      True         21\n",
       " 3   NeuralNetFastAI_r127_BAG_L1      0.992  ...      True         77\n",
       " 4   NeuralNetFastAI_r187_BAG_L1      0.992  ...      True         86\n",
       " ..                          ...        ...  ...       ...        ...\n",
       " 85     RandomForest_r127_BAG_L1      0.956  ...      True         49\n",
       " 86         ExtraTrees_r4_BAG_L1      0.948  ...      True         55\n",
       " 87        KNeighborsDist_BAG_L1      0.908  ...      True          2\n",
       " 88      RandomForest_r34_BAG_L1      0.868  ...      True         51\n",
       " 89        KNeighborsUnif_BAG_L1      0.856  ...      True          1\n",
       " \n",
       " [90 rows x 10 columns]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3fdbbe-928b-4c45-8c86-ac76066d88f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_r180_BAG_L1</td>\n",
       "      <td>0.992</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>22.084476</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>22.084476</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI_r172_BAG_L1</td>\n",
       "      <td>0.992</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.073780</td>\n",
       "      <td>5.961272</td>\n",
       "      <td>0.073780</td>\n",
       "      <td>5.961272</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI_r102_BAG_L1</td>\n",
       "      <td>0.992</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.075737</td>\n",
       "      <td>6.076989</td>\n",
       "      <td>0.075737</td>\n",
       "      <td>6.076989</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI_r127_BAG_L1</td>\n",
       "      <td>0.992</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.075875</td>\n",
       "      <td>6.033528</td>\n",
       "      <td>0.075875</td>\n",
       "      <td>6.033528</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetFastAI_r187_BAG_L1</td>\n",
       "      <td>0.992</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.078020</td>\n",
       "      <td>7.443452</td>\n",
       "      <td>0.078020</td>\n",
       "      <td>7.443452</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>RandomForest_r127_BAG_L1</td>\n",
       "      <td>0.956</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.089840</td>\n",
       "      <td>1.728445</td>\n",
       "      <td>0.089840</td>\n",
       "      <td>1.728445</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ExtraTrees_r4_BAG_L1</td>\n",
       "      <td>0.948</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.089224</td>\n",
       "      <td>0.660131</td>\n",
       "      <td>0.089224</td>\n",
       "      <td>0.660131</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.908</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.006468</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.006468</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>RandomForest_r34_BAG_L1</td>\n",
       "      <td>0.868</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.103782</td>\n",
       "      <td>0.842023</td>\n",
       "      <td>0.103782</td>\n",
       "      <td>0.842023</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.856</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.047665</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.047665</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  score_val  ... can_infer  fit_order\n",
       "0          CatBoost_r180_BAG_L1      0.992  ...      True         75\n",
       "1   NeuralNetFastAI_r172_BAG_L1      0.992  ...      True         74\n",
       "2   NeuralNetFastAI_r102_BAG_L1      0.992  ...      True         21\n",
       "3   NeuralNetFastAI_r127_BAG_L1      0.992  ...      True         77\n",
       "4   NeuralNetFastAI_r187_BAG_L1      0.992  ...      True         86\n",
       "..                          ...        ...  ...       ...        ...\n",
       "85     RandomForest_r127_BAG_L1      0.956  ...      True         49\n",
       "86         ExtraTrees_r4_BAG_L1      0.948  ...      True         55\n",
       "87        KNeighborsDist_BAG_L1      0.908  ...      True          2\n",
       "88      RandomForest_r34_BAG_L1      0.868  ...      True         51\n",
       "89        KNeighborsUnif_BAG_L1      0.856  ...      True          1\n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3882a5-429d-4f4a-a7b6-08a3d7d4c32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
